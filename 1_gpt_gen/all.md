1. 逻辑架构
1.1. 大多数基于网络的客户端/服务器工具或服务器都有类似的服务
1.1.1. 连接处理
1.1.2. 身份验证
1.1.3. 确保安全性
1.2. 核心层
1.2.1. 查询解析、分析、优化、以及所有的内置函数
1.2.2. 跨存储引擎的功能
1.2.2.1. 存储过程
1.2.2.2. 触发器
1.2.2.3. 视图
1.3. 存储引擎层
1.3.1. 存储引擎负责MySQL中数据的存储和提取
1.3.2. 和GNU/Linux下的各种文件系统一样，每种存储引擎都有其优势和劣势
1.3.3. 优化器并不关心表使用的是什么存储引擎，但存储引擎对于查询优化是有影响的
2. 查询缓存
2.1. query cache
2.2. 随着并发性的增加，查询缓存成为一个让人诟病的瓶颈
2.3. MySQL 5.7.20版本开始，查询缓存已经被官方标注为被弃用的特性
2.4. 在8.0版本中被完全移除
2.5. 缓存被频繁请求的结果集依然是一个很好的实践
2.5.1. 一个流行的设计模式是在memcached或Redis中缓存数据
3. 并发控制
3.1. 只要有多个查询需要同时修改数据，就会产生并发控制问题
3.2. 并发控制的级别
3.2.1. 服务器级别
3.2.2. 存储引擎级别
3.3. 读写锁
3.3.1. 从电子表格中读取数据不会有什么麻烦，即使很多人同时读取也不会有问题
3.3.2. 读锁（read lock）
3.3.2.1. 共享锁（shared lock）
3.3.2.2. 资源上的读锁是共享的，或者说是相互不阻塞的
3.3.3. 写锁（write lock）
3.3.3.1. 排他锁（exclusive lock）
3.3.3.2. 写锁则是排他的，也就是说，一个写锁既会阻塞读锁也会阻塞其他的写锁
3.3.3.3. 只有这样才能确保在特定的时间点只有一个客户端能执行写入，并防止其他客户端读取正在写入的资源
3.3.3.3.1. 这是出于安全策略的考虑
3.3.4. 处理并发读/写访问的系统通常实现一个由两种锁类型组成的锁系统
3.3.5. 在实际的数据库系统中，每时每刻都在发生锁定
3.3.6. 如果数据库服务器以可接受的方式执行，锁的管理速度足够快，那么不会引起客户端的感知
3.3.7. 锁是数据库实现一致性保证的方法
3.4. 锁的粒度
3.4.1. 一种提高共享资源并发性的方式就是让锁定对象更有选择性
3.4.2. 尽量只锁定包含需要修改的部分数据，而不是所有的资源
3.4.3. 只对需要修改的数据片段进行精确的锁定
3.4.4. 让锁定的数据量最小化，理论上就能保证在给定资源上同时进行更改操作，只要被修改的数据彼此不冲突即可
3.4.5. 如果系统花费大量的时间来管理锁，而不是存取数据，那么系统的性能可能会受影响
3.5. 锁策略
3.5.1. 锁定策略是锁开销和数据安全性之间的平衡，这种平衡会影响性能
3.5.2. 表锁（table lock）
3.5.2.1. MySQL中最基本也是开销最小的锁策略
3.5.2.2. 它会锁定整张表
3.5.2.2.1. 只有没有人执行写操作时，其他读取的客户端才能获得读锁，读锁之间不会相互阻塞
3.5.2.3. 写锁队列和读锁队列是分开的，但写锁队列的优先级绝对高于读队列
3.5.3. 行级锁（row lock）
3.5.3.1. 行级锁是在存储引擎而不是服务器中实现的
3.5.3.2. 可以最大程度地支持并发处理（也带来了最大的锁开销）
3.5.3.3. 允许多人同时编辑不同的行，而不会阻塞彼此
3.5.3.4. 一般都是在表中施加行级锁（row level lock），为了在锁比较多的情况下尽可能地提供更好的性能，锁的实现方式非常复杂
3.5.3.5. 服务器可以执行更多的并发写操作
3.5.3.6. 代价是需要承担更多开销
3.5.3.6.1. 跟踪谁拥有这些行级锁
3.5.3.6.2. 已经锁定了多长时间
3.5.3.6.3. 行级锁的类型
3.5.3.6.4. 何时该清理不再需要的行级锁
4. 事务
4.1. 事务就是一组SQL语句，作为一个工作单元以原子方式进行处理
4.2. 作为事务的一组语句，要么全部执行成功，要么全部执行失败
4.3. 存在高度复杂且缓慢的两阶段提交系统的典型原因
4.3.1. 为了应对各种失败场景
4.3.1.1. 连接可能会断开
4.3.1.2. 会超时
4.3.1.3. 数据库服务器在操作执行过程中会崩溃
4.4. ACID
4.4.1. 原子性（atomicity）
4.4.1.1. 一个事务必须被视为一个不可分割的工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚
4.4.2. 一致性（consistency）
4.4.2.1. 数据库总是从一个一致性状态转换到下一个一致性状态
4.4.3. 隔离性（isolation）
4.4.3.1. 一个事务所做的修改在最终提交以前，对其他事务是不可见的，这就是隔离性带来的结果
4.4.4. 持久性（durability）
4.4.4.1. 一旦提交，事务所做的修改就会被永久保存到数据库中
4.4.4.2. 不可能有100%的持久性保障
4.4.4.3. 如果数据库本身就能做到真正的持久性，那么备份又怎么能增加持久性?
4.4.5. ACID事务和InnoDB引擎提供的保证是MySQL中最强大、最成熟的特性之一
4.4.6. 除非系统通过严格的ACID测试，否则空谈事务的概念是不够的
4.5. 隔离级别
4.5.1. READ UNCOMMITTED（未提交读）
4.5.1.1. 在事务中可以查看其他事务中还没有提交的修改
4.5.1.2. 从性能上来说，READ UNCOMMITTED不会比其他级别好太多，却缺乏其他级别的很多好处
4.5.1.3. 在实际应用中一般很少使用
4.5.1.4. 读取未提交的数据，也称为脏读（dirty read）
4.5.2. READ COMMITTED（提交读）
4.5.2.1. 大多数数据库系统的默认隔离级别是READ   COMMITTED
4.5.2.1.1. MySQL不是
4.5.2.2. 一个事务可以看到其他事务在它开始之后提交的修改
4.5.2.3. 在该事务提交之前，其所做的任何修改对其他事务都是不可见的
4.5.2.4. 允许不可重复读（nonrepeatable read）
4.5.2.4.1. 这意味着同一事务中两次执行相同语句，可能会看到不同的数据结果
4.5.3. REPEATABLE READ（可重复读）
4.5.3.1. MySQL默认的事务隔离级别
4.5.3.2. 保证了在同一个事务中多次读取相同行数据的结果是一样的
4.5.3.3. 无法解决另外一个幻读（phantom read）
4.5.3.4. 幻读指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行（phantom row)
4.5.3.5. InnoDB和XtraDB存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）解决了幻读的问题
4.5.4. SERIALIZABLE（可串行化）
4.5.4.1. 最高的隔离级别
4.5.4.2. 通过强制事务按序执行，使不同事务之间不可能产生冲突，从而解决了幻读问题
4.5.4.3. 实际应用中很少用到这个隔离级别，除非需要严格确保数据安全且可以接受并发性能下降的结果
4.5.5. 隔离级别之间的利与弊
5. 死锁
5.1. 两个或多个事务相互持有和请求相同资源上的锁，产生了循环依赖
5.2. InnoDB存储引擎，检测到循环依赖后会立即返回一个错误信息
5.2.1. 死锁将表现为非常缓慢的查询
5.3. 一旦发生死锁，如果不回滚其中一个事务（部分或全部），就无法打破死锁
5.4. InnoDB目前处理死锁的方式是将持有最少行级排他锁的事务回滚
5.4.1. 这是一种最容易回滚的近似算法
5.5. 死锁的产生有双重原因
5.5.1. 真正的数据冲突，这种情况通常很难避免
5.5.2. 完全是由于存储引擎的实现方式导致的
1. 三管齐下
1.1. 不做、少做、快速地做
1.2. 如果查询太大，服务端会拒绝接收更多的数据并抛出相应错误
1.3. 如果查询写得很糟糕，即使库表结构再合理、索引再合适，也无法实现高性能
1.4. 查询优化、索引优化、库表结构优化需要齐头并进，一个不落
1.5. Percona Toolkit中的pt-archiver工具
2. 响应时间
2.1. 如果把查询看作一个任务，那么它由一系列子任务组成，每个子任务都会消耗一定的时间
2.2. 如果要优化查询，实际上要优化其子任务，要么消除其中一些子任务，要么减少子任务的执行次数，要么让子任务运行得更快
2.3. 优化查询的目的就是减少和消除这些操作所花费的时间
2.4. 查询需要在不同的地方花费时间
2.4.1. 网络、CPU计算、生成统计信息和执行计划、锁等待（互斥等待）等操作
2.4.2. 尤其是向底层存储引擎检索数据的调用操作，这些调用需要在内存操作、CPU操作和内存不足时导致的I/O操作上消耗时间
2.5. 两部分之和：服务时间和排队时间
2.5.1. 服务时间是指数据库处理这个查询真正花了多长时间
2.5.2. 排队时间是指服务器因为等待某些资源而没有真正执行查询的时间——可能是等I/O操作完成，也可能是等待行锁
2.6. 响应时间既可能是一个问题的结果也可能是一个问题的原因，不同案例情况不同
2.7. 实际上可以使用“快速上限估计”法来估算查询的响应时间
2.7.1. 了解这个查询需要哪些索引以及它的执行计划是什么
2.7.2. 计算大概需要多少个顺序和随机I/O
2.7.3. 用其乘以在具体硬件条件下一次I/O的消耗时间
2.7.4. 把这些消耗都加起来
2.7.5. 获得一个大概参考值来判断当前响应时间是不是一个合理的值
3. 查询的生命周期
3.1. 从客户端到服务器，然后在服务器上进行语法解析，生成执行计划，执行，并给客户端返回结果
3.2. “执行”可以被认为是整个生命周期中最重要的阶段
4. 优化数据访问
4.1. 如果性能很差，最常见的原因是访问的数据太多
4.2. 是否在检索大量且不必要的数据
4.2.1. 访问了太多的行
4.2.2. 访问了太多的列
4.3. 确认MySQL服务器层是否在分析大量不需要的数据行
4.3.1. 会请求超过实际需要的数据，然后这些多余的数据会被应用程序丢弃
4.3.2. 消耗应用服务器的CPU和内存资源
4.4. 一个常见的错误是，常常会误以为MySQL只会返回需要的数据，实际上MySQL却是先返回全部结果集再进行计算
4.4.1. 最简单有效的解决方法就是在这样的查询后面加上LIMIT子句
4.5. 每次看到SELECT*的时候都需要用怀疑的眼光审视，是不是真的需要返回全部的列，很可能不是必需的
4.5.1. 取出全部列，会让优化器无法完成索引覆盖扫描这类优化
4.5.2. 严格禁止SELECT*的写法，这样做有时候还能避免某些列被修改而带来的问题
4.6. 查询返回超过需要的数据也不总是坏事
4.7. 重复查询相同的数据
4.7.1. 当初次查询的时候将这个数据缓存起来，需要的时候从缓存中取出，这样性能显然会更好
4.8. 检查慢日志记录是找出扫描行数过多的查询的好办法
4.9. 扫描的行数和返回的行数
4.9.1. 查看该查询扫描的行数能够说明该查询找到需要的数据的效率高不高
4.9.2. 理想情况下扫描的行数和返回的行数应该是相同的，但实际中这种“美事”并不多
4.9.3. 扫描的行数与返回的行数的比率通常很低，一般在1：1到10：1之间，不过有时候这个值也可能非常非常大
4.10. 访问类型有很多种，从全表扫描到索引扫描、范围扫描、唯一索引查询、常数引用等
4.10.1. 访问方式可能无须扫描就能返回结果
4.10.2. 访问方式可能需要扫描很多行才能返回一行结果
4.10.3. 没办法找到合适的访问类型，那么最好的解决办法通常就是增加一个合适的索引
4.11. 应用WHERE条件
4.11.1. 在索引中使用WHERE条件来过滤不匹配的记录
4.11.1.1. 在存储引擎层完成的
4.11.2. 使用索引覆盖扫描（在Extra列中出现了Using index）来返回记录
4.11.2.1. 直接从索引中过滤不需要的记录并返回命中的结
4.11.2.2. 在MySQL服务器层完成的，但无须再回表查询记录
4.11.3. 从数据表中返回数据，然后过滤不满足条件的记录（在Extra列中出现Using where）
4.11.3.1. 在MySQL服务器层完成
4.11.3.2. 需要先从数据表中读出记录然后过滤
4.12. 不是说增加索引就能让扫描的行数等于返回的行数
4.13. 优化
4.13.1. 使用索引覆盖扫描，把所有需要用的列都放到索引中，这样存储引擎无须回表获取对应行就可以返回结果了
4.13.2. 改变库表结构
4.13.2.1. 使用单独的汇总表
4.13.3. 重写这个复杂的查询，让MySQL优化器能够以更优化的方式执行
5. 重构查询的方式
5.1. 在优化有问题的查询时，目标应该是找到获得实际需要的结果的替代方法
5.1.1. 但这并不一定意味着从MySQL返回完全相同的结果集
5.1.2. 可以将查询转换为返回相同结果的等价形式，以获得更好的性能
5.2. 以前人们总是认为网络通信、查询解析和优化是一件代价很高的事情
5.2.1. 对于MySQL并不适用
5.2.2. MySQL从设计上让连接和断开连接都很轻量，在返回一个小的查询结果方面很高效
5.2.3. 现代的网络速度比以前要快很多，能在很大程度上降低延迟
5.3. 在MySQL内部，每秒能够扫描内存中上百万行的数据
5.3.1. MySQL响应数据给客户端就慢得多了
5.4. 在其他条件都相同的时候，使用尽可能少的查询当然是更好的
5.4.1. 将一个大查询分解为多个小查询是很有必要的
5.4.2. 如果在一个查询能够胜任时还将其写成多个独立的查询是不明智的
5.5. 切分查询
5.5.1. 删除旧的数据就是一个很好的例子
5.5.1.1. 定期清除大量数据时，如果用一个大的语句一次性完成的话，则可能需要一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询
5.5.1.2. 将一个大的DELETE语句切分成多个较小的查询可以尽可能小地影响MySQL的性能，同时还可以降低MySQL复制的延迟
5.5.2. 一次删除一万行数据一般来说是一个比较高效而且对服务器影响最小的做法（如果是事务型引擎，很多时候小事务能够更高效）
5.5.3. 如果每次删除数据后，都暂停一会儿再做下一次删除，也可以将服务器上原本一次性的压力分散到一个很长的时间段中，可以大大降低对服务器的影响，还可以大大减少删除时锁的持有时间
5.6. 分解联接查询
5.6.1. 很多高性能的应用都会对联接查询进行分解
5.6.2. 可以对每一个表进行一次单表查询，然后将结果在应用程序中进行联接
5.6.3. 让缓存的效率更高
5.6.4. 将查询分解后，执行单个查询可以减少锁的竞争
5.6.5. 在应用层做联接，可以更容易对数据库进行拆分，更容易做到高性能和可扩展
5.6.6. 查询本身的效率也可能会有所提升
5.6.6.1. 使用IN()代替联接查询，可以让MySQL按照ID顺序进行查询，这可能比随机的联接要更高效
5.6.7. 可以减少对冗余记录的访问
5.6.7.1. 在应用层做联接查询，意味着对于某条记录应用只需要查询一次，而在数据库中做联接查询，则可能需要重复地访问一部分数据
1. MySQL的客户端/服务器通信协议
1.1. MySQL的客户端和服务器之间的通信协议是“半双工”的
1.2. 在任何时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，这两个动作不能同时发生
1.3. 当查询的语句很长的时候，参数max_allowed_packet就特别重要了
1.4. 一般的服务器响应给用户的数据通常很多，由多个数据包组成
1.5. 当服务器开始响应客户端请求时，客户端必须完整地接收整个返回结果，而不能简单地只取前面几条结果，然后让服务器停止发送数据
1.5.1. 在必要的时候一定要在查询中加上LIMIT限制
1.6. 当客户端从服务器取数据时，看起来是一个拉数据的过程，但实际上是MySQL在向客户端推送数据的过程
1.7. MySQL通常需要等所有的数据都已经发送给客户端才能释放这条查询所占用的资源，所以接收全部结果并缓存通常可以减少服务器的压力，让查询能够早点结束、早点释放相应的资源
1.8. 当使用多数连接MySQL的库函数从MySQL获取数据时，其结果看起来都像是从MySQL服务器获取数据，而实际上都是从这个库函数的缓存获取数据
1.9. 如果能够尽早开始处理这些结果集，就能大大减少内存的消耗，在这种情况下可以不使用缓存来记录结果而是直接处理
1.9.1. 对于服务器来说，需要查询完成后才能释放资源，所以在和客户端交互的整个过程中，服务器的资源都是被这个查询所占用的
1.9.2. 用mysql_unbuffered_query()代替mysql_query()，PHP则不会缓存结果
2. SHOW FULL PROCESSLIST命令
2.1. 该命令返回结果中的Command列，其就表示当前的状态
2.2. Sleep
2.2.1. 线程正在等待客户端发送新的请求
2.3. Query
2.3.1. 线程正在执行查询或者正在将结果发送给客户端
2.4. Locked
2.4.1. 在MySQL服务器层，该线程正在等待表锁
2.5. Analyzing and statistics
2.5.1. 线程正在检查存储引擎的统计信息，并优化查询
2.6. Copying to tmp table [on disk]
2.6.1. 线程正在执行查询，并且将其结果集复制到一个临时表中
2.6.2. 么是在做GROUP BY操作
2.6.3. 要么是在进行文件排序操作
2.6.4. 或者是在进行UNION操作
2.6.5. “on disk”标记，那表示MySQL正在将一个内存临时表放到磁盘上
2.7. Sorting result
2.7.1. 线程正在对结果集进行排序
3. 导致MySQL优化器选择错误的执行计划
3.1. 统计信息不准确
3.1.1. MySQL服务器依赖存储引擎提供的统计信息来评估成本，但是有的存储引擎提供的信息是准确的，有的偏差可能非常大
3.2. 成本指标并不完全等同于运行查询的实际成本
3.3. MySQL的最优可能和你想的最优不一样
3.3.1. MySQL只是基于其成本模型选择最优的执行计划，而有些时候这并不是最快的执行方式
3.4. MySQL从不考虑其他并发执行的查询，这可能会影响到当前查询的速度
3.5. MySQL也并不是任何时候都是基于成本的优化
3.5.1. 如果存在全文搜索的MATCH()子句，则在存在FULLTEXT索引的时候就使用全文索引
3.5.2. 即使有时候使用其他索引和WHERE条件可以远比这种方式要快，MySQL也仍然会使用对应的全文索引
3.6. MySQL不会考虑不受其控制的操作的成本
3.6.1. 执行存储函数或者用户自定义函数的成本
4. 优化策略
4.1. 静态优化
4.1.1. 不依赖于特别的数值
4.1.2. 在第一次完成后就一直有效，即使使用不同的参数重复执行查询也不会发生变化
4.1.3. 编译时优化
4.2. 动态优化
4.2.1. 和查询的上下文有关
4.2.2. 在每次查询的时候都重新评估
4.2.3. 运行时优化
5. 优化类型
5.1. 重新定义联接表的顺序
5.1.1. 数据表的联接并不总是按照在查询中指定的顺序进行
5.2. 将外联接转化成内联接
5.2.1. 并不是所有的OUTER JOIN语句都必须以外联接的方式执行
5.3. 使用代数等价变换规则
5.4. 优化COUNT()、MIN()和MAX()
5.4.1. 索引和列是否可为空通常可以帮助MySQL优化这类表达式
5.5. 预估并转化为常数表达式
5.5.1. 当MySQL检测到一个表达式可以转化为常数的时候，就会一直把该表达式作为常数进行优化处理
5.6. 覆盖索引扫描
5.6.1. 当索引中的列包含所有查询中需要使用的列的时候，MySQL就可以使用索引返回需要的数据，而无须查询对应的数据行
5.7. 子查询优化
5.7.1. 将子查询转换为一种效率更高的形式，从而减少多个查询多次对数据进行访问
5.8. 提前终止查询
5.8.1. 在发现已经满足查询需求的时候，MySQL总是能够立刻终止查询
5.8.2. 一个典型的例子就是当使用了LIMIT子句的时候
5.9. 类似这种“不同值/不存在”的优化一般可用于DISTINCT、NOT EXIST()或者LEFT JOIN类型的查询
5.10. ⑩等值传播
5.11. ⑾列表IN()的比较
5.11.1. IN()完全等同于多个OR条件的子句，因为这两者是完全等价的
5.11.2. 在MySQL中这点是不成立的，MySQL将IN()列表中的数据先进行排序，然后通过二分查找的方式来确定列表中的值是否满足条件，这是一个O（logn）复杂度的操作，等价地转换成OR查询的复杂度为O（n），对于IN()列表中有大量取值的时候，MySQL的处理速度将会更快
6. 表和索引的统计信息
6.1. 存储引擎则给优化器提供对应的统计信息，包括：每个表或者索引有多少个页面、每个表的每个索引的基数是多少、数据行和索引的长度是多少、索引的分布信息等
7. 联接查询
7.1. MySQL对任何联接都执行嵌套循环联接操作，即MySQL先在一个表中循环取出单条数据，然后再嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为止
7.2. 在MySQL 8.0.20版本之后，已经不再使用基于块的嵌套循环联接操作，取而代之的是哈希联接
7.2.1. 这让联接操作性能变得更好，特别是当数据集可以全部存储在内存时
7.3. 通常多表联接的时候，可以有多种不同的联接顺序来获得相同的执行结果
7.4. 执行计划
7.4.1. 如果你对某个查询执行EXPLAIN EXTENDED后，再执行SHOWWARNINGS，就可以看到重构出的查询
7.5. 让查询进行更少的回溯和重读操作
7.5.1. 可以使用STRAIGHT_JOIN关键字重写查询，让优化器按照你认为的最优的联接顺序执行
7.6. n个表的联接可能有n的阶乘种联接顺序
7.6.1. 优化器选择使用“贪婪”搜索的方式查找“最优”的联接顺序
7.6.2. 当需要联接的表超过optimizer_search_depth的限制的时候，就会选择“贪婪”搜索模式了
7.7. 查询不能重新排序，联接优化器可以利用这一点通过消除选择来减小搜索空间
1. “快速、精确和实现简单”
1.1. 三者永远只能满足其二，必须舍掉一个
2. 排序优化
2.1. 无论如何排序都是一个成本很高的操作，所以从性能角度考虑，应尽可能避免排序或者尽可能避免对大量数据进行排序
2.2. 文件排序（filesort）
2.2.1. MySQL需要自己进行排序，如果数据量小则在内存中进行，如果数据量大则需要使用磁盘
2.2.2. 完全是在内存中排序不需要任何磁盘文件时也是如此
2.3. 排序算法
2.3.1. 两次传输排序（旧版本使用）
2.3.1.1. 读取行指针和需要排序的字段，对其进行排序，然后再根据排序结果读取所需要的数据行
2.3.1.2. 即需要从数据表中读取两次数据，第二次读取数据的时候，因为是读取排序列进行排序后的所有记录，这会产生大量的随机I/O，所以两次传输排序的成本非常高
2.3.2. 单次传输排序（新版本使用）
2.3.2.1. 先读取查询所需要的所有列，然后再根据给定列进行排序，最后直接返回排序结果
2.3.2.2. 不再需要从数据表中读取两次数据，对于I/O密集型的应用来说，这样做的效率高了很多
2.3.2.3. 只需要一次顺序I/O就可读取所有的数据，而无须任何的随机I/O
2.4. MySQL在进行文件排序时需要使用的临时存储空间可能会比想象的要大得多
2.5. 如果使用utf8mb4字符集，那么MySQL将会为每个字符预留4字节
2.6. 如果查询中有LIMIT的话，LIMIT也会在文件排序之后应用，所以即使需要返回较少的数据，临时表和需要排序的数据量仍然会非常大
3. 将结果返回给客户端
3.1. 执行查询的最后一个阶段是将结果返回给客户端
3.2. MySQL将结果集返回客户端是一个增量且逐步返回的过程
3.2.1. 服务器端无须存储太多的结果，也就不会因为要返回太多结果而消耗太多内存
4. MySQL查询优化器的局限性
4.1. MySQL查询优化器只对少部分查询不适用，而且我们往往可以通过改写查询让MySQL高效地完成工作
4.2. UNION的限制
4.2.1. MySQL无法将限制条件从UNION的外层“下推”到内层，这使得原本能够限制部分返回结果的条件无法应用到内层查询的优化上
4.2.2. 从临时表中取出数据的顺序并不是一定的，所以如果想获得正确的顺序，还需要在最后的LIMIT操作前加上一个全局的ORDER BY操作
4.3. 等值传递
4.3.1. 优化器通过将列表复制到所有相关表中的相应列来“共享”列表
4.4. 并行执行
4.4.1. MySQL无法利用多核特性来并行执行查询
5. 优化特定类型的查询
5.1. 多数优化技巧都和特定的版本有关，所以对于未来MySQL的版本未必适用
5.2. 优化COUNT()查询
5.2.1. COUNT()是一个特殊的函数
5.2.1.1. 可以统计某列的值的数量
5.2.1.2. 可以统计行数
5.2.2. 用COUNT（）的时候，这种情况下通配符并不会像我们猜想的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计所有的行数
5.2.2.1. 如果想要知道结果中的行数，应该始终使用COUNT（*），这样可以更清晰地传达意图，避免糟糕的性能表现
5.2.3. 常见的错误之一是当需要统计行数时，在COUNT()函数的括号内指定了列名
5.2.4. 计算精确值非常复杂，而计算近似值则非常简单
5.2.4.1. 可以增加类似Memcached这样的外部缓存系统
5.3. 优化联接查询
5.3.1. 确保ON或者USING子句中的列上有索引
5.3.1.1. 没有用到的索引只会带来额外的负担
5.3.2. 确保任何GROUP BY和ORDER BY中的表达式只涉及一个表中的列，这样MySQL才有可能使用索引来优化这个过程
5.3.3. 当升级MySQL的时候需要注意：联接语法、运算符优先级等其他可能会发生变化的地方
5.3.4. 使用WITH ROLLUP优化GROUP BY
5.3.4.1. 分组查询的一个变种就是要求MySQL对返回的分组结果再做一次超级聚合
5.3.4.2. 在应用程序中做超级聚合是更好的，虽然这需要给客户端返回更多的结果
5.3.4.3. 最好的办法是尽可能地将WITH ROLLUP功能转移到应用程序中处理
5.4. 优化LIMIT和OFFSET子句
5.4.1. 在系统中需要进行分页操作的时候，我们通常会使用LIMIT加上偏移量的办法实现，同时加上合适的ORDER BY子句
5.4.2. 在页面中限制分页的数量
5.4.3. 优化大偏移量的性能
5.4.4. 尽可能地使用索引覆盖扫描，而不是查询所有的行
5.4.5. 将LIMIT查询转换为已知位置的查询，让MySQL通过范围扫描获得对应的结果
5.4.6. OFFSET的问题
5.4.6.1. 会导致MySQL扫描大量不需要的行然后再抛弃掉
5.4.6.2. 可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET
5.4.6.2.1. 无论翻页到多么靠后，其性能都会很好
5.4.6.3. 冗余表，冗余表只包含主键列和需要做排序的数据列
5.5. 更好的设计
5.5.1. 将具体的页数换成“下一页”按钮
5.5.1.1. 假设每页显示20条记录，那么我们每次查询时都是用LIMIT返回21条记录并只显示20条
5.5.1.2. 如果第21条存在，那么就显示“下一页”按钮，否则就说明没有更多的数据，也就无须显示“下一页”按钮了
5.5.2. 先获取并缓存较多的数据
5.5.2.1. 缓存1000条——然后每次分页都从这个缓存中获取
5.5.2.2. 如果结果集小于1000，就可以在页面上显示所有的分页链接，因为数据都在缓存中，所以这样做不会对性能造成影响
5.5.2.3. 如果结果集大于1000，则可以在页面上设计一个额外的“找到的结果多于1000条”之类的按钮
5.5.3. 比每次生成全部结果集再抛弃不需要的数据的效率高很多
5.6. 优化SQL CALC FOUND ROWS
5.6.1. 在LIMIT语句中加上SQL_CALC_FOUND_ROWS提示（hint），这样就可以获得去掉LIMIT以后满足条件的行数，因此可以作为分页的总数
5.6.2. 加上这个提示以后，不管是否需要，MySQL都会扫描所有满足条件的行，然后再抛弃掉不需要的行，而不是在满足LIMIT的行数后就终止扫描
5.6.3. 该提示的代价可能非常高
5.6.4. 当需要精确结果的时候，再单独使用COUNT（*）来满足需求，这时如果能够使用索引覆盖扫描则通常也会比SQL_CALC_FOUND_ROWS快得多
5.7. 优化UNION查询
5.7.1. 经常需要手工地将WHERE、LIMIT、ORDER BY等子句“下推”到UNION的各个子查询中，以便优化器可以充分利用这些条件进行优化
5.7.2. 除非你确实需要服务器消除重复的行，否则一定要使用UNION ALL
1. 每个人都知道需要备份，但并不是每个人都能意识到需要的是可恢复的备份
1.1. 如果你没有提前做好备份规划，也许以后会发现已经错失了一些最佳的选择
1.2. 在服务器已经配置好以后，才想起应该使用LVM，以便获取文件系统的快照——但这时已经太迟了
1.3. 如果你没有计划做定期的恢复演练，当真的需要恢复时，就会发现并没有那么顺利
2. 不要掉进副本就是备份的陷阱
2.1. 副本对生成备份而言是一个干涉较少的源，但它不是备份本身
2.2. 确保备份可以通过DROP TABLE测试
2.2.1. “遭受黑客攻击”的测试
2.2.2. 能通过数据中心失败的测试
2.2.3. 如果是基于备库生成备份，需要通过从源重建备份，并从那时起强制执行super_read_only来确保你的所有副本是一致的
3. 裸文件备份
3.1. 物理备份
3.2. 文件系统中的文件副本
4. 逻辑备份
4.1. 重建数据所需的SQL语句
5. 推荐的备份方式
5.1. Percona XtraBackup进行裸文件备份
5.2. mydumper进行逻辑备份
5.3. 无侵入地实现二进制的原始数据备份
5.3.1. 备份可以通过启动mysqld实例检查所有的表来进行验证
5.3.2. 建议备份二进制日志
5.3.2.1. 尽可能久地保留多份备份的数据和二进制文件
5.3.2.2. 即使最近的备份无法使用，还可以使用较老的备份来执行恢复或者创建新的副本
6. 整体备份和恢复策略要点
6.1. 安全
6.1.1. 访问备份的入口
6.1.2. 恢复数据的权限
6.1.3. 文件是否需要加密
6.2. 备份存储在哪里
6.2.1. 离源数据多远
6.2.1.1. 在一块不同的磁盘上
6.2.1.2. 一台不同的服务器上
6.2.1.3. 离线存储
6.2.2. 如何将数据从源头移动到目的地
6.3. 保留策略、审计、法律要求，以及相关的条款
6.4. 存储解决方案和介质，压缩，以及增量备份
6.5. 存储的格式
6.6. 对备份的监控和报告
6.7. 存储层内置备份功能
6.7.1. 其他专用设备
7. 热备份
7.1. 不需要任何的服务停机时间
8. 还原
8.1. 从备份文件中获取数据，可以将这些文件加载到MySQL里，也可以将这些文件放置到MySQL期望的路径中
9. 恢复
9.1. 当某些异常发生后对一个系统或其部分的拯救
9.2. 从备份中还原数据
9.3. 使服务器完全恢复功能的所有必要步骤
9.4. 存储引擎的崩溃恢复要求数据和日志文件一致
9.4.1. 要确保数据文件中只包含已经提交的事务所做的修改，恢复操作会将日志中还没有应用到数据文件的事务重新执行
10. 备份的理由
10.1. 灾难恢复
10.1.1. 硬件故障
10.1.2. 一个不经意的Bug导致数据损坏
10.1.3. 服务器及其数据由于某些原因不可获取或无法使用
10.1.4. 某人偶然连错服务器执行了一个ALTER TABLE操作
10.1.5. 机房大楼被烧毁
10.1.6. 恶意的黑客攻击
10.2. 人们改变想法
10.2.1. 经常会在删除某些数据后又想恢复这些数据
10.3. 审计
10.3.1. 需要知道数据或Schema在过去的某个时间点是什么样的
10.4. 测试
10.4.1. 最简单的基于实际数据来测试的方法是，定期用最新的生产环境数据更新测试服务器
10.4.2. 只要把备份文件还原到测试服务器上即可
11. 备份误区
11.1. 复制就是备份
11.1.1. 复制不是备份
11.1.2. 使用RAID阵列也不是备份
11.1.3. 不是备份，也不是备份的替代品
11.2. 快照就是备份
11.2.1. 无论是LVM、ZFS还是SAN快照，都不是真正的备份
11.2.1.1. 不包含数据的完整副本
11.2.2. 快照是写时复制
11.2.2.1. 只包含数据的实时副本与快照发生时的数据之间的差异
11.2.3. 如果备份是用于某些特殊用户的，那么快照可能是一个非常好的方法
12. 定义恢复需求
12.1. 备份在先
12.1.1. 只有已经做了备份才可能恢复，因此在构建系统时，注意力自然会集中在备份上
12.2. 备份由脚本和任务自动完成
12.3. 备份是日常任务，但恢复常常发生在危急情形下
12.4. 安全的需要
12.4.1. 做异地备份，可能需要对备份数据进行加密，或采取其他措施来进行保护
12.5. 需要培养几个人并有计划地让他们互为备份，这样就无须由一个不合格的人来恢复数据
12.6. 恢复点目标（PRO）
12.7. 恢复时间目标（RTO）
13. 备份方案
13.1. 备份仅是数据的一个副本，但是受限于应用程序的要求、MySQL的存储引擎架构，以及系统配置等因素，复制一份数据变得很困难
13.2. 对数据丢失的承受力越强，备份越简单
13.2.1. 一个“宽松”的基于故障时间点的恢复需求意味着需要重建数据，直到“足够接近”问题发生的时刻
13.2.2. 一个“硬性”的需求意味着不能容忍丢失任何一个已提交的事务，即使某些可怕的事情发生（例如，服务器着火了）
13.2.2.1. 将二进制日志保存在一个独立的SAN卷
13.2.2.2. 使用DRBD磁盘复制
13.3. 在生产实践中，对于大数据库来说，裸文件备份是必需的：逻辑备份太慢并受到资源限制，从逻辑备份中恢复需要很长时间
13.3.1. 基于快照的备份，例如Percona   XtraBackup和MySQL  EnterpriseBackup，是最好的选择
13.3.2. 对于较小的数据库，逻辑备份可以很好地胜任
13.4. 保留多个备份集
13.5. 定期从逻辑备份（或者裸文件备份）中抽取数据进行恢复测试
13.6. 保存二进制日志用于基于故障时间点的恢复
13.6.1. 将expire_logs_days参数的值设置得足够大，至少确保可以从最近两次裸文件备份中做基于时间点的恢复
13.6.2. 保持源运行且不应用任何二进制日志的情况下创建一个副本
13.6.3. 使备份二进制日志独立于过期设置，二进制日志需要保存在备份中足够长的时间，以便能从最近的逻辑备份中进行恢复
13.6.4. 重放二进制日志来恢复到想要的时间点
13.7. 完全不借助备份工具本身来监控备份和备份的过程
13.7.1. 需要额外验证备份是否正常
13.8. 通过演练整个恢复过程来测试备份和恢复
13.8.1. 测算恢复所需要的资源（CPU、磁盘空间、实际时间，以及网络带宽等）
13.9. 考虑安全性
1. 在线备份
2. 离线备份
2.1. 关闭MySQL做备份是最简单、最安全的
2.2. 所有获取一致性副本的方法中最好的
2.3. 损坏或不一致的风险最小
2.4. 根本不用关心InnoDB缓冲池中的脏页或其他缓存
2.5. 不需要担心数据在尝试备份的过程中被修改
2.5.1. 服务器不对应用提供访问
3. 备份时间
3.1. 将备份复制到目的地需要多久
4. 备份负载
4.1. 在将备份复制到目的地时对服务器性能的影响有多大
4.2. 在备份服务器上压缩而不是在MySQL服务器上
4.3. Percona XtraBackup和MySQL Enterprise Backup这样的工具都有限流选项，可在使用p v时加--rate-limit选项来限制备份脚本的吞吐量
5. 牺牲其一以增强另外一个
6. 恢复时间
6.1. 把备份镜像从存储位置复制到MySQL服务器、重放二进制日志等，需要多久
7. 逻辑备份
7.1. 导出
7.2. 以一种MySQL能够解析的格式来包含数据
7.2.1. SQL语句
7.2.2. 以某个符号分隔的文本
7.3. 优点
7.3.1. 逻辑备份备份的文件是可以用编辑器或像grep和sed之类的命令查看和操作的普通文件
7.3.2. 恢复非常简单
7.3.3. 可以通过网络来备份和恢复，也就是说，可以在与MySQL主机不同的另外一台机器上操作
7.3.4. 可以在类似云数据库这样不能访问底层文件系统的系统中使用
7.3.5. 灵活
7.3.6. 与存储引擎无关
7.3.6.1. 消除了底层数据存储引擎的差异
7.3.7. 有助于避免数据损坏
7.3.7.1. 如果MySQL在内存中的数据还没有损坏，当不能得到一个正常的裸文件备份时，或许可以得到一个可以信赖的逻辑备份
7.4. 缺点
7.4.1. 必须由数据库服务器完成生成逻辑备份的工作，因此要占用更多的CPU周期
7.4.1.1. 某些场景下比数据库文件本身更大
7.4.2. 无法保证导出后再还原出来的一定是同样的数据
7.4.2.1. 浮点表示的问题、软件Bug等都会导致问题
7.4.3. 从逻辑备份中还原需要MySQL加载和解释语句，将它们转化为存储格式，并重建索引，所有这一切会很慢
7.4.3.1. MySQL中导出数据和通过SQL语句将其加载回去的庞大开销
7.4.3.2. 如果使用逻辑备份，测试恢复需要的时间将非常重要
7.4.3.3. 逻辑备份最可怕的地方就是不确定的还原时间
8. 裸文件备份
8.1. 原始文件是指存放于硬盘上的文件
8.2. 直接复制原始文件
8.3. 优点
8.3.1. 基于文件的物理备份，它只需将需要的文件复制到其他地方即可完成备份，不需要其他额外的工作来生成原始文件
8.3.2. 非常容易跨平台、操作系统和MySQL版本工作
8.3.3. 从裸文件备份中恢复会更快
8.3.3.1. MySQL服务器不需要执行任何SQL语句或构建索引
8.3.3.2. 如果有很大的InnoDB表，无法完全缓存到内存中，则裸文件备份的恢复要快得多
8.3.3.2.1. 至少要快一个数量级
8.4. 缺点
8.4.1. InnoDB的原始文件通常比相应的逻辑备份要大得多
8.4.1.1. 表空间往往包含很多未使用的空间
8.4.2. 不总是可以跨平台、操作系统及MySQL版本的
8.4.2.1. 文件名大小写敏感和浮点格式是可能会遇到麻烦的
8.4.2.2. 对于需要长期保留或者是用于满足法律合规要求的备份，尽量不要完全依赖裸文件备份
8.4.2.3. 每隔一段时间需要做一次逻辑备份
8.4.3. 除非经过测试，不要假定备份（特别是裸文件备份）是正常的
8.4.3.1. CHECK TABLES
8.4.3.2. 不建议仅对文件运行innochecksum
9. 混合使用
9.1. 使用裸文件备份
9.2. 用得到的数据启动MySQL服务器实例并运行mysqlcheck
9.3. 周期性地使用mysqldump执行逻辑备份
9.4. 优点是不会使生产服务器在导出时有过度负担
9.5. 如果能够方便地利用文件系统的快照，也可以生成一个快照，将该快照复制到另外一台服务器上并释放，然后测试原始文件，再执行逻辑备份
10. 备份什么
10.1. 恢复的需求决定需要备份什么
10.2. 最简单的策略是只备份数据和表定义，但这是一个最低的要求
10.3. 非显著数据
10.3.1. 二进制日志和InnoDB事务日志
10.3.2. 在理想情况下，应该把整个数据目录和MySQL一起备份起来
10.4. 代码
10.4.1. 现代的MySQL服务器可以存储许多代码，例如，触发器和存储过程
10.4.2. 实际是存放在mysql数据库中的
10.5. 服务器配置
10.5.1. 对于服务器配置来说，备份中对生产服务器至关重要的任何外部配置，都十分重要
10.6. 选定的操作系统文件
10.6.1. 在UNIX服务器上，这可能包括cron任务、用户和组的配置、管理脚本，以及sudo规则
11. 部分备份
11.1. 一般不包含完整的数据集
11.1.1. 因为某些数据没有改变
11.1.2. 对减少服务器开销、备份时间及备份空间而言都很适合
11.2. Percona XtraBackup和MySQL Enterprise Backup，仍然会扫描服务器上的所有数据块，因而并不会节约太多的开销
11.2.1. 确实会减少一定量的备份时间和大量用于压缩的CPU时间
11.2.2. 会减少磁盘空间的使用
11.3. 差异备份
11.3.1. 自上次全备份后所有改变的部分而做的备份
11.4. 增量备份
11.4.1. 对自任意类型的上次备份后的所有修改做的备份
11.4.2. 缺点
11.4.2.1. 会增加恢复的复杂性
11.4.2.2. 额外的风险
11.4.2.3. 更长的恢复时间
12. 建议
12.1. 使用Percona XtraBackup和MySQL Enterprise Backup中的增量备份特性
12.2. 备份二进制日志
12.2.1. 在每次备份后使用FLUSH LOGS来开始记录一个新的二进制日志，这样就只需要备份新的二进制日志
12.3. 如果有一些“引用”表，例如，包含不同语种、各个月的名称列表，或者州或区域的简写等，可以考虑将它们单独放在一个数据库中，这样就不需要每次都备份这些表
12.3.1. 一个更好的选择可能是把这些数据放到程序代码中，而不是保存在数据库中
12.4. 某些数据根本不需要备份
12.4.1. 相对于从全备份中可能获得的快速恢复时间，避免备份可以节约更多时间开销
12.4.2. 临时数据也不用备份
12.5. 备份所有的数据，然后发送到一个有去重特性的地方
12.6. 如果可以做全备份，考虑到简便性，建议尽量做全备份
12.6.1. 建议至少一周一次
13. 复制
13.1. 从副本中备份最大的好处是可以不干扰源库，避免在源库上增加额外的负载
13.1.1. 这是一个建立副本服务器的好理由，即使不需要用它做负载均衡或提供高可用性
13.2. 用GTID是非常明智的
13.2.1. 避免了必须保存有关复制过程的所有信息
13.3. 故意将一个副本延迟复制一段时间对于某些灾难场景非常有用
13.4. 源库与副本数据不匹配是很常见的，并且MySQL没有方法检测这个问题
13.4.1. 唯一方法是使用Percona Toolkit中的pt-table-checksum之类的工具
13.4.2. 防止这种情况的最好方法是使用super_read_only来确保只有复制可以写入副本
13.5. 复制不是备份
1. 二进制日志
1.1. 服务器的二进制日志是需要备份的最重要元素之一
1.2. 对于基于时间点的恢复是必需的，并且通常比数据要小，所以更容易被进行频繁的备份
1.3. 如果有某个时间点的数据备份和所有从那时以后的二进制日志，就可以重放从上次全备份以来的二进制日志并“向前回滚”所有的变更
1.4. 如果你不能承受丢失超过30分钟数据的代价，至少要每30分钟就备份一次
1.5. 需要制定日志的过期策略以防止磁盘被二进制日志写满
1.6. 日志增长的大小取决于工作负载和日志格式（基于行的日志会产生更大的日志记录）
1.7. 保留日志对于设置复制、分析服务器负载、审计和从上次全备份中按时间点进行恢复，都很有帮助
1.8. 使用binlog_expire_logs_seconds变量来通知MySQL定期清理日志，而不应该手动地去删除这些文件
1.9. MySQL服务器通过查看修改时间而不是内容来决定要清除哪些文件
2. 工具
2.1. MySQL Enterprise Backup
2.1.1. MySQL官方的备份工具
2.2. Percona XtraBackup
2.2.1. 开源并且免费的
2.2.2. 支持类似流、增量、压缩和多线程（并行）备份操作
2.2.3. 降低在高负载系统上进行备份的影响
2.2.4. 当使用Percona XtraBackup进行备份时，它会记录日志序列号（LSN），并使用该序列号对备份文件执行崩溃恢复
2.3. mydumper
2.3.1. 一个多线程（并发）的MySQL备份和恢复工具集
2.4. mysqldump
3. 备份数据
3.1. 应该最大化地利用网络、磁盘和CPU的能力以尽可能快地完成备份
3.2. 主要的问题
3.2.1. 将库表结构和数据存储在一起
3.2.2. 巨大的SQL语句
3.2.2.1. 服务器解析和执行SQL语句的工作量非常大，所以加载数据时会非常慢
3.2.3. 单个巨大的文件
3.2.4. 逻辑备份的成本很高
3.2.4.1. 在生产环境使用逻辑备份可能很难满足要求
3.2.4.2. 如果使用逻辑备份，强烈建议考虑使用mydumper，以避免单线程备份的一些问题，并实际测试使用该工具备份对数据库的影响
3.3. 文件系统快照
3.3.1. 一种非常好的在线备份方法
3.3.2. FreeBSD的文件系统、ZFS文件系统、GNU/Linux的逻辑卷管理（LVM）
3.3.3. 创建快照是减少必须持有锁的时间的一个简单方法；释放锁后，必须将文件复制到备份中
3.3.4. 使用文件系统快照，有些时候甚至无须任何锁定，就可以创建InnoDB的备份快照
3.3.5. 文件系统快照不是取得数据瞬间副本的唯一方法
3.3.5.1. 另外一个选择是RAID分裂
3.3.6. 快照不仅仅用于备份，还有很多其他用途
4. 恢复数据
4.1. 步骤
4.1.1. 停止MySQL服务器
4.1.2. 记录服务器的配置和文件权限
4.1.3. 将数据从备份中移到MySQL数据目录
4.1.4. 改变配置
4.1.5. 改变文件权限
4.1.6. 以限制访问模式重启服务器，等待其完成启动
4.1.7. 载入逻辑备份文件
4.1.8. 检查和重放二进制日志
4.1.9. 检测已经还原的数据
4.1.10. ⑩以完全权限重启服务器
4.2. 恢复逻辑备份
4.2.1. 如果恢复的是逻辑备份而不是裸文件备份，则与使用操作系统将文件简单地复制到适当位置的方式不同，需要使用MySQL服务器本身来将数据加载到表中
4.2.2. 一个值得倡导的规则是，恢复过程越难越复杂，也就越需要逻辑备份的保护
4.2.3. 应付某些无法使用裸文件备份的场景，准备好逻辑备份总是值得推荐的
4.3. 从快照中恢复
4.3.1. 恢复裸文件备份往往非常直接
4.3.2. 如果使用InnoDB的file-per-table特性（innodb_file_per_table），InnoDB会将每个表的数据和索引存储于一个.ibd文件中
4.3.3. 最大的限制是，只能在当初备份的服务器上还原单个表
1. 概述
1.1. 复制解决的基本问题是让一台服务器的数据与其他服务器保持同步
1.2. 在源服务器（source server）上，任何数据修改和数据结构变更的事件（event）都会被写入日志文件中
1.3. 副本服务器从源服务器上的日志文件中读取这些事件并在本地重放执行
1.4. 一个异步处理的过程
1.4.1. 不能保证副本服务器上的数据是最新的
1.4.2. 复制延迟（副本数据和最新数据之间的时间差）也并没有上限
1.5. MySQL复制是其内置的一把“瑞士军刀”
1.6. MySQL的复制基本上是向后兼容的
1.6.1. 新版本的服务器可以作为老版本的服务器的副本
1.6.2. 老版本的服务器作为新版本的服务器的副本通常是不可行的
1.7. 通过复制可以将读操作指向副本来获得更好的读扩展性
1.7.1. 并不适合通过复制来扩展写操作
1.8. 在一主库多副本库的架构中，写操作会被执行多次，这时候整个系统的性能取决于写入最慢的那部分
1.9. 在复制架构中，读取和重放日志事件是解耦的
1.9.1. 允许读取日志和重放日志异步进行
1.9.2. I/O线程和SQL线程都是可以独立运行的
2. 用途
2.1. 数据分发
2.1.1. 不会对带宽造成很大的压力
2.1.2. 基于行的复制会比传统的基于语句的复制模式的带宽压力更大
2.1.3. 如果为了保持很低的复制延迟，最好有一个稳定的、低延迟连接
2.2. 读流量扩展
2.2.1. 可以将读操作分布到多台服务器上，实现对读密集型应用的优化
2.2.2. 对于小规模的应用，可以简单地对机器名做硬编码或使用DNS轮询
2.3. 备份
2.3.1. 一项有助于备份的有价值的技术，但副本不是备份，也不能够取代备份
2.4. 分析与报告
2.4.1. 为报告/分析（在线分析处理，OLAP）查询使用专用的副本是一项很好的策略
2.4.2. 可以很好地隔离此类查询产生的压力，以避免对满足外部客户需求的在线业务产生影响
2.5. 高可用性和故障切换
2.5.1. 有助于避免MySQL成为应用程序中的单点故障
2.5.2. 一个包含复制的设计良好的故障切换系统能够显著地缩短宕机时间
2.6. MySQL升级测试
2.6.1. 先使用一个更高版本的MySQL作为副本，确保查询能够在此副本上按照预期执行，再升级所有的实例
3. 步骤
3.1. 源端把数据更改记录到二进制日志中，称之为“二进制日志事件”（binary log events）
3.2. 副本将源上的日志复制到自己的中继日志中
3.3. 副本读取中继日志中的事件，将其重放到副本数据之上
4. 原理
4.1. 复制格式
4.1.1. 基于语句的
4.1.1.1. 通过记录所有在源端执行的数据变更语句来实现的
4.1.1.2. 简单且紧凑
4.1.1.3. 一条更新了大量数据的SQL语句，在二进制日志中可能仅仅需要几十字节存储
4.1.1.4. “不确定性”的SQL语句问题
4.1.1.4.1. 如果在源和副本上，记录的排序不同，这条SQL语句在源和副本上删除的100条记录就会不同，这将导致数据不一致
4.1.1.5. 除非某些场景下明确需要临时使用基于语句的复制
4.1.2. 基于行的
4.1.2.1. 每条被改变的记录都会作为事件被写入二进制日志
4.1.2.2. 让二进制日志的大小发生巨大的增长
4.1.2.3. 建议坚持使用基于行的复制
4.1.2.3.1. 提供了最安全的数据复制方法
4.1.3. 混合模式
4.1.3.1. the mixed method
4.1.3.2. 事件的写入，默认使用基于语句的格式，仅在需要时才切换到基于行的格式
4.1.3.3. 在写入每个事件时会有很多的判断条件，以确定使用哪种格式，而这也会导致二进制日志中出现不可预测的事件
4.1.3.4. 不使用
4.2. 全局事务标识符
4.2.1. GTID
4.2.2. 使用GTID，源服务器提交的每个事务都被分配一个唯一标识符
4.2.3. 由server_uuid和一个递增的事务编号组成的
4.2.4. 当事务被写入二进制日志时，GTID也随之被写入
4.2.4.1. 当SQL线程提交事务时，它也会将GTID标记为执行完成
4.2.5. GTID解决了运行MySQL复制的一个令人痛苦的问题：处理日志文件和位置
4.2.6. 强烈建议在数据库中启用GTID
4.3. 崩溃后的复制安全
4.3.1. innodb_flush_log_at_trx_commit=1
4.3.1.1. 可以保障每个事务日志都被同步地写到磁盘
4.3.1.2. 这是一个符合ACID要求的配置，将最大限度地保护你的数据
4.3.1.3. 二进制日志事件首先被提交，然后事务将被提交并写入磁盘
4.3.1.4. 此参数设置为1将增加磁盘写入操作的频次，同时确保数据的持久性
4.3.2. sync_binlog=1
4.3.2.1. 控制MySQL将二进制日志数据同步到磁盘的频率
4.3.2.2. 设置为1意味着在每次事务执行的时候都会把二进制日志同步写入磁盘
4.3.2.3. 可以防止在服务器崩溃时丢失事务
4.3.2.4. 会增加磁盘写入量
4.3.3. relay_log_info_repository=TABLE
4.3.3.1. 信息将被转移到MySQL本身的InnoDB表中，允许复制更新同一事务中的事务和中继日志信息
4.3.3.2. 会在一个原子操作中完成，并有助于崩溃恢复
4.3.4. relay_log_recovery=ON
4.3.4.1. 使得副本服务器在检测到崩溃时会丢弃所有本地中继日志，并从源服务器中获取丢失的数据
4.3.4.2. 确保了在崩溃中发生的磁盘上的任何损坏或不完整的中继日志都是可恢复的
4.3.4.3. 不再需要配置sync_relay_log
4.3.4.3.1. 因为在发生崩溃时，中继日志将被删除，也就无须花费额外的操作将它们同步到磁盘
4.4. 延迟复制
4.4.1. 某些副本有一些延迟反而是有好处的
4.4.2. 可以让副本中的数据保持在线并且持续运行，但同时落后于源数据库数小时或者数天
4.4.3. 配置语句是CHANGEREPLICATION SOURCE TO，配置选项为SOURCE_DELAY
4.4.4. 场景
4.4.4.1. 删除了一个表
4.4.4.1.1. 从备份中恢复可能需要几个小时
4.4.4.1.2. 如果使用了延迟复制的副本，则可以找到DROP TABLE语句对应的GTID，使副本服务器的复制运行到表被删除之前的时间点，这会大大减少修复时间
4.5. 多线程复制
4.5.1. 在副本端运行多个SQL线程，从而加快本地中继日志的应用
4.5.2. 两种模式
4.5.2.1. DATABASE模式
4.5.2.1.1. 使用多线程更新不同的数据库
4.5.2.1.2. 但不会有两个线程同时更新同一个数据库
4.5.2.1.3. 将数据分布在MySQL的多个数据库中，则可以同时并且一致地更新它们，这种模式非常有效
4.5.2.2. LOGICAL_CLOCK模式
4.5.2.2.1. 允许对同一个数据库进行并行更新，只要它们都是同一个二进制日志组提交的一部分
4.5.2.2.2. 人工延迟的配置参数
4.5.2.2.2.1. binlog_group_commit_sync_delay（以微秒为单位的延迟）
4.5.2.2.2.2. binlog_group_commit_sync_no_delay_count（决定中止等待之前要等待的事务数）
4.5.2.2.2.3. 确保你的副本配置了参数replica_preserve_commit_order，这样就不会出现无序提交的问题
4.6. 半同步复制
4.6.1. 在启用半同步复制后，源在完成每个事务提交时，都需要确保事务至少被一个副本所接收
4.6.2. 需要确认副本已收到并成功将其写入自己的中继日志（但不一定应用到本地数据）
4.6.3. 如果在一定时间范围内没有副本确认事务，MySQL将恢复到标准的异步复制模式
4.6.4. 半同步复制不是一种防止数据丢失的方法，而是可以让你拥有更具弹性的故障切换的更大工具集的一部分
4.6.5. 建议不要依赖该功能来保证数据完整性
4.7. 复制过滤器
4.7.1. 可以让副本仅复制一部分数据
4.7.2. 复制过滤器是一颗定时炸弹
4.7.3. 从源上的二进制日志中过滤事件
4.7.3.1. binlog_do_db
4.7.3.2. binlog_ignore_db
4.7.3.3. 不仅有可能破坏复制，还会使从备份中进行时间点恢复变得不可能
4.7.3.3.1. 在大多数情况下都不应该使用它们
4.7.4. 从副本上的中继日志中过滤事件
4.7.4.1. replication_*选项在SQL线程从中继日志中读取事件时过滤事件
1. 复制切换
1.1. 复制是高可用性的基础
1.1.1. 总是保留一份持续更新的副本数据，会让灾难恢复更简单
1.2. “切换副本”（promoting a replica）和“故障切换”（failing over）是同义词
1.2.1. 意味着源服务器不再接收写入，并将副本提升为新的源服务器
1.3. 计划内切换
1.3.1. 常见原因
1.3.1.1. 安全补丁
1.3.1.2. 内核更新
1.3.1.3. 一些配置选项更改后需要重新启动才能生效
1.3.2. 步骤
1.3.2.1. 确定将哪个副本切换为新的源
1.3.2.1.1. 一个包含所有数据的副本
1.3.2.2. 检查延时，确保延时在秒级别
1.3.2.3. 通过设置super_read_only停止数据写入源服务器
1.3.2.4. 等待副本与目标完全同步
1.3.2.4.1. 通过比较GTID来确定
1.3.2.5. 在目标（需要切换为源的副本）上取消read_only设置
1.3.2.6. 将应用流量切换到目标上
1.3.2.7. 将所有副本重新指向新的源，包括刚刚被降级为副本的服务器
1.3.2.7.1. 配置了GTID和AUTO_POSITION=1
1.4. 计划外切换
1.4.1. 只要时间够长，每个系统都会因软件或硬件而出现故障
1.4.2. 当故障发生在承担写入的源服务器上时，会对用户体验产生重大影响
1.4.3. 这时候不再存在一个实时运行的源服务器了
1.4.4. 步骤
1.4.4.1. 确定需要切换的副本
1.4.4.1.1. 择数据最完整的副本
1.4.4.2. 在目标上关闭read_only设置
1.4.4.3. 将应用流量切换到目标上
1.4.4.4. 将所有副本重新指向新源（目标服务器），包括恢复后的原来提供服务的源服务器
1.4.4.4.1. 切换前的源服务器再次启动时，需要默认启用super_read_only
1.4.4.4.1.1. 防止任何意外的写入
1.5. 切换时的权衡
1.5.1. 很难知道切换后的目标（新的源服务器）可能丢失了多少数据
1.5.2. 有时不进行故障切换可能是更好的策略
1.5.3. 等待恢复的好处不会丢失任何数据，并且所有副本将继续从中断的地方工作
2. 复制拓扑
2.1. 几乎任何一个源和副本都可以配置MySQL复制
2.2. 主动/被动模式
2.2.1. 应用将所有读取和写入都指向单个源服务器
2.2.2. 不用担心复制延迟的问题
2.2.3. 可以防止应用程序不接受读取延迟数据的问题
2.2.4. 配置
2.2.4.1. 应该尽量让源和副本在CPU、内存等方面具有相同的配置
2.2.4.2. 副本上使用相同的硬件和软件配置就可以确保能够支持切换之前的应用流量容量和吞吐量
2.2.5. 冗余
2.2.5.1. 在物理硬件环境中，推荐使用至少三台服务器的n+2冗余
2.2.5.2. 如果数据足够少，或者可以轻松复制数据，也可以使用至少两台服务器的n+1冗余，否则还是建议n+2
2.2.5.3. 如果无法在源服务器上进行备份操作，可以使用其中一个副本作为备份服务器
2.2.6. 注意事项
2.2.6.1. 实际上是将读扩展绑定到单台服务器的容量上
2.2.6.2. 如果达到读扩展上限
2.2.6.2.1. 则必须演进到更复杂的拓扑
2.2.6.2.1.1. 主动/只读池配置
2.2.6.2.2. 否则就不得不利用分片来减少源上的读取压力
2.3. 主动/只读池配置
2.3.1. 将所有写入指向源服务器
2.3.2. 根据应用程序的需要，读取则可以被发送到源服务器或只读池
2.3.3. 只读池可以实现读取密集型应用程序的读水平扩展
2.3.4. 由于源上的复制请求，水平扩展能力会受到限制
2.3.5. 配置
2.3.5.1. 如果随着时间的推移，只读池在持续增长，则可以让副本用不同的硬件配置来优化成本
2.3.5.2. 将流量进行加权，运行在更好的硬件配置的副本上可以承担更多的流量
2.3.6. 冗余
2.3.6.1. 应满足先前提出的要求，还需要至少一台服务器可以充当故障切换的目标
2.3.7. 注意事项
2.3.7.1. 只读池的大小会决定管理的复杂度，以及何时应该考虑自动化
2.4. 不推荐的拓扑架构
2.4.1. 双源主动-主动架构
2.4.1.1. 双向复制
2.4.1.2. 涉及两台服务器，每台服务器都配置为源和另一台的副本
2.4.1.3. 一对协同源
2.4.2. 双源主动-被动模式
2.4.2.1. 主动-主动模式下的双源服务器有一个变种
2.4.2.2. 其中一台服务器是只读的“被动”服务器
2.4.3. 带有副本的双源模式
2.4.3.1. 两个可写的源只会带来麻烦
2.4.4. 环形复制
2.4.4.1. 具有三个或更多个源，其中每台服务器都在环中，它之前的服务器是它的副本，它之后的服务器作为它的源
2.4.4.2. 循环复制
2.4.5. 多源复制
3. 复制管理和维护
3.1. 在数据量很小而且写入负载一致的时候，通常不太需要经常查看复制延迟或者复制中断相关的问题
3.2. 复制监控
3.2.1. 复制同时需要源和副本上的磁盘空间
3.2.2. 监控复制的状态和错误
3.2.2.1. 如果复制线程没有正常运行，那么可以查看报错信息，以确定下一步应该做什么来修复错误
3.2.3. 延迟复制的实际延迟
3.2.3.1. 太长的延迟可能会使其使用起来更加耗时
3.3. 观测复制延迟
3.3.1. 副本与源之间的复制延迟是多少
3.3.2. 最好的解决方案是心跳记录，它需要在源上每秒更新一次时间戳
3.3.2.1. 创建了一个方便的时间戳，展示副本中的数据在什么时间点是最新的
3.3.2.2. Percona Toolkit中包含的pt-heartbeat脚本是当前最流行的复制心跳实现方案
3.3.2.3. 二进制日志中的复制心跳记录可用于许多目的
3.4. 确定副本数据的一致性
3.4.1. 副本始终是其源的精确复制减去其复制延迟的部分
3.4.2. 副本与源不一致的原因
3.4.2.1. 意外写入副本
3.4.2.2. 使用双源复制，双方都写入了数据
3.4.2.3. 非确定性语句和基于语句的复制
3.4.2.4. 当运行在弱持久化模式时MySQL崩溃
3.4.2.5. MySQL中的Bug
3.4.3. 建议遵循的规则或配置
3.4.3.1. 在副本上，始终启用super_read_only
3.4.3.1.1. 使用read_only可以防止没有SUPER权限的用户写入，但这不会阻止DBA在没有意识到他们在副本上的情况下运行DELETE或ALTER
3.4.3.1.2. super_read_only设置只允许复制写入，是运行副本的最安全方式
3.4.3.2. 使用基于行的复制或确定性语句
3.4.3.2.1. 基于行的复制是复制数据的最一致的方式
3.4.3.2.2. 使用ORDER BY，使行顺序具有确定性
3.4.3.3. 不要尝试同时写入复制拓扑中的多台服务器
3.4.3.3.1. 最实用的复制拓扑是使用一个源，执行所有写入操作，以及一个或多个副本，可选择地执行读取操作
4. 复制问题和解决方案
4.1. 使用副本扩展读取操作，使用分片技术扩展写入操作
4.2. 源端二进制日志损坏
4.2.1. 如果源上的二进制日志已被损坏，那么别无选择，只能重建副本
4.3. 非唯一的服务器ID
4.3.1. 如果你不小心配置了具有相同服务器ID的两个副本，不仔细观察的话，它们似乎可以正常工作
4.3.2. 在源服务器上，任何时候都只能看到两个副本中的一个
4.3.3. 解决此问题的唯一方法是在设置副本时要小心
4.3.3.1. 创建副本到服务器ID映射的规范列表很有帮助
4.3.3.2. 如果副本完全位于一个子网中，则可以使用每台机器IP地址的最后一个八位字节来作为唯一ID
4.4. 未配置服务器ID
4.4.1. MySQL将显示为使用CHANGEREPLICATION SOURCE TO配置了复制，但不会允许启动副本
4.4.2. 你可能会从SELECT＠＠server_id中获得一个值，但这只是一个默认值
4.4.2.1. 必须显式设置该值
4.5. 临时表丢失
4.5.1. 临时表在某些场景中使用起来很方便，但不幸的是，它们与基于语句的复制不兼容
4.5.2. 如果副本崩溃或将其关闭，则副本线程正在使用的任何临时表都会消失
4.5.3. 当重新启动副本时，引用丢失的临时表的任何相关语句都将失败
4.5.4. 最好的方法是使用基于行的复制
4.5.4.1. 其次是统一命名临时表（例如，以temporary_为前缀），然后使用复制规则完全跳过复制临时表
4.6. 没有复制所有变更
4.6.1. 如果误用SET SQL_LOG_BIN=0或不了解复制过滤规则，可能会导致副本不会执行源上发生的某些变更
4.7. 复制延迟过大
4.7.1. 多线程复制
4.7.2. 使用分片技术
4.7.2.1. 使用分片技术将写入分散到多个源也是一种非常有效的策略
4.7.3. 临时降低持久化要求
4.7.3.1. 如果复制延迟主要是由于写入操作导致的，则可以临时设置sync_binlog=0和innodb_flush_log_at_trx_commit=0以提高复制速度
4.7.3.2. 最好只在副本上执行此操作，如果此副本也用于执行备份操作，则更改这些设置可能会使你无法从备份中恢复完整的数据
4.7.3.3. 一种可能的策略是监控SHOW REPLICA STATUS命令中的Seconds_behind_source值，当它超过某个阈值时
4.7.3.3.1. 验证是否启用了super_read_only，以确保服务器是不可写副本
4.7.3.3.2. 更改sync_binlog和innodb_flush_log_at_trx_commit的配置以减少写操作
4.7.3.3.3. 定期检查SHOW REPLICA STATUS以获取Seconds_behind_source的值
4.7.3.3.4. 当延迟低于可接受的阈值时，将持久性相关参数恢复到正常值
4.8. 来自源服务器的超大数据包
4.8.1. 当源服务器的max_allowed_packet大小与副本不匹配时，可能会出现另一个难以跟踪的复制问题
4.8.2. 源服务器可以记录副本认为过大的数据包，当副本检索该二进制日志事件时，它可能会遇到各种问题，其中包括无休止的错误循环、重试或中继日志中的损坏
4.9. 磁盘空间耗尽
4.9.1. 当源服务器执行大量LOAD DATA INFILE语句并在副本上启用log_replica_updates时
4.9.2. 复制延迟越大，用于已从源端获取但尚未执行的中继日志占用的磁盘空间就越多
4.9.3. 可以通过监控磁盘使用情况并设置relay_log_space参数来防止这些错误出现
4.10. 复制的限制
4.10.1. 因为MySQL自身固有的一些限制，无论有没有出现明确的报错，MySQL复制都可能失败或不同步
4.10.2. 服务器中的bug
4.10.2.1. MySQL服务器的许多大版本历史上都有复制方面的bug
4.10.2.1.1. 尤其是在大版本的第一个版本中
1. 增长
1.1. 在高速的业务环境中，流量可能逐年增长几个数量级，环境会变得更加复杂，随之而来的数据需求也会快速增加
1.2. 扩展Web服务器
1.2.1. 在负载均衡的后端添加更多的服务器节点，而这通常就是扩展We b服务器的全部工作
2. 可扩展性
2.1. 系统支撑不断增长的流量的能力
2.1.1. 可扩展性就是能够通过增加资源来提升容量的能力
2.2. 一个系统扩展能力的好坏可以用成本和简单性来衡量
2.3. 容量是一个和可扩展性相关的概念
2.3.1. 系统容量表示在一定时间内能够完成的工作量
2.3.2. 容量可以简单地被认为是处理负载的能力，从几个不同的角度来考虑负载很有帮助
2.4. 系统的最大吞吐量并不等同于容量
2.4.1. 如果达到最大吞吐量，则性能会下降，响应时间会变得不可接受且非常不稳定
2.5. 即使系统性能不是很高也可以具备可扩展性
2.6. 数据量
2.6.1. 应用所能累积的大量数据是可扩展性最普遍的一个挑战
2.6.2. 应用从不删除任何数据
2.7. 用户数
2.7.1. 当查询依赖于用户间的关系时（关系的数量可以用N*（N-1）/2来计算，这里N表示用户数
2.8. 用户活跃度
2.8.1. 不是所有的用户的活跃度都相同，并且用户活跃度也不总是不变的
2.9. 相关数据集的大小
2.9.1. 社交网站经常会面临由那些人气很旺的用户组或朋友很多的用户所带来的挑战
2.10. 可扩展性的原则之一是避免节点之间的交叉访问
2.11. 请专注于确定业务是读限制的还是写限制的
3. 扩展MySQL的理论思想
3.1. 优先使用更小的实例
3.1.1. 按功能、水平方式或两者兼而有之来分割数据
3.1.2. 当故障发生时，实例越小，所造成的影响面也越小
3.2. 通过复制和自动写故障切换来增强弹性
3.2.1. 在发生故障时，自动进行写入故障切换，并管理拓扑更改和对数据库节点的应用程序访问，以使写停机时间尽可能短
3.3. 通过半同步复制保证持久性
3.3.1. 相对于默认的异步复制
4. 读限制与写限制工作负载
4.1. 工作负载
4.1.1. 系统能达到的QPS数
4.1.2. 是所有类型的查询及其延迟的混合
4.2. 读限制工作负载
4.2.1. 读限制工作负载是指读取（SELECT）总流量超过服务器容量的工作负载
4.2.2. 单源主机
4.2.2.1. 增加更多应用节点可以扩展服务用户请求的客户端数
4.2.2.2. 最终会被单源数据库主机的能力所限制，该数据库主机将要负责响应所有的读取请求
4.2.2.3. 高CPU使用率意味着服务器正花费所有的时间处理查询
4.2.2.4. CPU的使用率越高，查询的延迟也会越长
4.2.3. 引入副本来扩展读流量
4.3. 写限制工作负载
4.3.1. 写限制工作负载则超过了服务器提供DML（INSERT、UPDATE、DELETE）操作的容量
4.3.2. 当写入量成为瓶颈时，必须开始考虑使用拆分数据的方法，以便在单独的子数据集上接受并行的写入
4.3.3. 仔细检查schema，确定是否存在读需求增长比其他写需求增长更快的表数据子集
5. 功能拆分
5.1. 基于业务中的“功能”来拆分数据是一项和业务背景强相关的任务，需要深入了解数据的用途
5.2. 指导原则
5.2.1. 不要根据工程团队的组织架构进行拆分，它会经常变动
5.2.2. 根据业务功能来拆分表
5.2.3. 不要回避处理数据中混杂了不同业务关系的问题，你不仅需要倡导数据分离，还需要倡导应用程序重构，并需要引入API来实现相互跨界的访问
6. 用读池扩展读
6.1. 集群中的副本可用于多个目的
6.1.1. 副本是故障切换的候选对象
6.2. 并非所有的复制副本都在池中，这是一种防止不同的读取工作负载相互影响的常见方法
6.3. 使用读池时会有不止一台服务读请求的数据库主机
6.4. 管理这些读池的一种非常常见的方法是使用负载均衡器来提供虚拟IP
6.4.1. 该IP充当所有要访问读副本的流量的中介
6.4.2. 技术包括HAProxy、自用主机时的硬件负载均衡器，或在公共云环境中运行时的网络负载均衡器
6.5. 在MySQL中，建议使用leastconn实现池节点之间的平衡
6.6. 服务发现是一个很好的选择，它可以自动发现新的主机并将其加入池列表
6.7. 每个副本池至少还要有三个节点服务于特定应用
6.8. 读池健康检查
6.9. 选择负载均衡器算法
6.9.1. 随机
6.9.1.1. 负载均衡器将每个请求定向到从可用服务器池中随机选择的服务器
6.9.2. 轮询
6.9.2.1. 负载均衡器以重复的顺序向服务器发送请求
6.9.3. 最少连接
6.9.3.1. 下一个连接指向拥有最少活跃连接的服务器
6.9.4. 最快响应
6.9.4.1. 处理请求最快的服务器接收下一个连接
6.9.5. 哈希
6.9.5.1. 负载均衡器对连接的源IP地址进行哈希处理，这会将地址映射到池中的一台服务器
6.9.6. 权重
6.9.6.1. 负载均衡器可以组合几种算法并添加权重
6.9.7. MySQL的最佳算法取决于具体工作负载
6.9.7.1. 一定要考虑在特殊情况下和日常情况下会发生什么
7. 排队机制
7.1. 使用设计上倾向于一致性而不是可用性的数据存储来扩展写事务时，扩展应用程序层会变得复杂得多
8. 使用分片扩展写
8.1. 分片意味着将数据切分成不同的、更小的数据库集群
8.1.1. 可以同时在更多的源主机上执行更多的写入操作
8.2. 功能分割（Functional partitioning）
8.2.1. 职责划分
8.2.2. 将不同的节点用于不同的任务
8.3. 数据分片（Data sharding）
8.3.1. 当今扩展超大型MySQL应用程序最常见和最成功的方法
8.4. 只对需要分片的数据进行切分
8.4.1. 通常是数据集中增长非常大的部分
8.5. 切分方案
8.5.1. 目标是使最重要和最频繁的查询接触到尽可能少的分片
8.6. 多个分片键
8.6.1. 复杂的数据模型使数据分片更加困难
8.7. 跨分片查询
8.7.1. 主动缓存通常也是有必要的
8.7.2. 设计间歇性运行的清理程序
8.8. Vitess
8.8.1. Vitess是面向MySQL的一个数据库集群系统
8.8.2. 一个用于运行数据库层的稳定平台，而不是一个临时的解决方案
8.8.3. 测试并记录向整个系统引入的延迟
8.8.4. 使用金丝雀部署模型
8.8.5. 特性
8.8.5.1. 支持水平分片，包括数据分片
8.8.5.2. 拓扑结构管理
8.8.5.3. 源节点故障切换管理
8.8.5.4. schema变更管理
8.8.5.5. 连接池
8.8.5.6. 查询重写
8.8.6. 组件
8.8.6.1. Vitess pod
8.8.6.1.1. 对一组数据库和Vitess相关部件的通用封装
8.8.6.2. VTGate
8.8.6.2.1. 为应用程序与操作员控制数据库实例访问提供的服务
8.8.6.3. VTTablet
8.8.6.3.1. 在Vitess管理的每个数据库实例上运行的代理
8.8.6.4. Topology
8.8.6.4.1. 在给定的pod中保存由Vitess管理的数据库实例清单以及相应的信息
8.8.6.4.2. 元数据存储
8.8.6.5. vtctl
8.8.6.5.1. 对Vitess pod进行操作更改的命令行工具
8.8.6.6. vtctld
8.8.6.6.1. 用来进行相同管理操作的图形化界面
8.9. ProxySQL
8.9.1. René Cannaò
8.9.1.1. MySQL的长期贡献者
8.9.2. 专门为MySQL协议编写的，通过通用公共许可证（GPL）发布
8.9.3. 提供了一个易于部署的抽象，比HAProxy更复杂，但在基础设施和复杂性方面的前期投入较少
8.9.4. 可以使用ProxySQL作为任何应用程序代码和MySQL实例的中间层
8.9.5. 一个很好的轻量级中间层，而且是分片感知的，还可以相应地路由应用程序连接
8.9.6. 按用户分片
8.9.7. 按schema分片
1. 如何构建数据库环境
1.1. 托管MySQL
1.2. VM上构建
1.3. 天下没有免费的午餐，每一个选择都伴随着一系列的权衡
2. 托管MySQL
2.1. 服务商提供了一个可访问的数据库设置程序，而不需要用户深入了解MySQL的具体细节
2.2. 使用托管MySQL将缺乏很多的可见性和控制能力
2.3. Aurora MySQL
2.4. 谷歌云平台（GCP）提供了CloudSQL
3. Aurora MySQL
3.1. Aurora MySQL是一个兼容MySQL的托管数据库
3.2. 将计算和存储分开，这使二者可以更灵活地单独扩展
3.3. Aurora中的所有托管解决方案都不兼容MySQL 8.0，而一些较旧的解决方案只兼容MySQL   5.6
3.4. 标准的Aurora产品是长期运行的计算实例，在其中选择一个实例类型
3.5. Aurora集群内的复制完全是Amazon专有的，而不是我们在Oracle MySQL中所知道和使用的复制
3.6. Aurora无服务器（Serverless）
3.6.1. Aurora MySQL的无服务器服务移除了长期运行的计算程序，并利用亚马逊的无服务器平台为数据库的计算层提供服务
3.7. Aurora全局数据库（Global Database）
3.8. Aurora多主节点（Multi-Master）
3.8.1. 多主节点是Aurora集群的一种特殊风格，可以同时在多个计算节点上接受写操作
4. GCP Cloud SQL
4.1. Cloud SQL是GCP的托管MySQL的产品
4.2. 它运行的是社区版MySQL，但特别禁用了某些功能，以实现产品的多租户和可管理
4.3. SUPER权限被禁用
4.4. 插件加载功能被禁用
4.5. 一些客户端也被禁用了，如mysqldump和mysqlimport
4.6. 原生的高可用性支持
4.7. 静止数据的原生加密
4.8. 使用多种方法实现灵活管理的升级
5. 虚拟机上的MySQL
5.1. 在虚拟机上运行MySQL就像在裸金属服务器上运行一样，你可以完整和彻底地控制所有的操作面
5.2. CPU
5.2.1. 虚拟CPU，而不是物理CPU
5.2.2. vCPU数量的计数公式
5.2.2.1. （CPU核的数量×95%CPU总使用量）×2
5.2.2.2. 建议将50%作为常规的使用率目标，最高可达到65%～70%
5.2.2.3. 如果维持在70%或更高的CPU使用率，将可能会看到延迟增加，此时应该考虑添加更多的CPU
5.2.3. 运行的是一个高流量的Web应用程序，则可能需要确保使用更新一代的芯片
5.3. 内存
5.3.1. RAM可以极大地影响MySQL的性能
5.3.2. 应为工作数据集选择最适合需求的机器规格，但错误的做法是RAM太多而不是不够
5.4. 网络性能
5.4.1. 如果有一个将读取大量数据的批处理进程，则你可能会发现在较小的机型上带宽已耗尽
5.5. 选择正确的磁盘类型
5.5.1. 高读密集型的工作负载将受益于更多的内存而不是磁盘性能，因为内存访问要快几个数量级
5.5.2. 如果工作集大于InnoDB缓冲池，那么将总是需要到磁盘上读取一些数据
5.5.3. 写密集型的工作负载总是会转移到磁盘上，这也是大多数人第一次看到磁盘瓶颈的地方
5.6. 磁盘的连接类型
5.6.1. 本地连接磁盘的好处是，其提供了令人难以置信的高性能和一致的吞吐量，但也很容易导致数据丢失
5.6.1.1. 被视为仅用于短暂数据的磁盘
5.6.2. 网络连接的磁盘可提供冗余和可靠性
5.6.2.1. 网络连接的磁盘可能会遇到本地连接的磁盘不会出现的停顿
5.6.3. 还可以使用磁盘快照技术让副本复制变得非常快，即使在许多TB级大小的磁盘上
5.6.3.1. 可以让需要在副本可用之前赶上来的复制的延迟降到最低
5.7. SSD与HDD
5.7.1. SSD的启动速度比HDD快两到三倍
5.7.2. 如果启动时间很重要，特别是在停机或重新启动的情况下，那么请始终使用SSD
5.8. IOPS和吞吐量
5.8.1. Percona Toolkit包中的pt-diskstats
5.9. 只允许服务器恢复在线和复制，以让它自己自然地重新连接
5.9.1. 使用SSD引导磁盘来允许尽可能快地重新启动。通常系统会在5分钟内恢复在线
5.9.2. 禁止长达5分钟时间内的任何服务器宕机的告警通知，以使系统完全重启并恢复正常
5.9.3. 如果源服务器重新启动，你可以编写一个选项来动态关闭read_only标志，从而让写入在没有人工干预的情况下继续进行
5.9.4. 通过自动地向可能需要了解中断的团队或渠道发送邮件或消息，来让沟通最大化
5.10. 建议将操作系统和MySQL数据分开
5.10.1. 磁盘快照将仅限于MySQL数据，并且不包含任何操作系统信息
5.10.2. 在使用网络连接的磁盘的情况下，可以轻松地断开磁盘的连接并重新连接到另一台机器
5.10.3. 对于网络连接的磁盘，还可以升级或替换操作系统，而不必将数据重新复制到文件系统中
5.11. 备份二进制日志
5.11.1. 将二进制日志发送到一个存储桶中
5.11.2. 在桶上设置生命周期控制，以便在一段确定的时间后自动清除旧文件
5.11.3. 阻止在特定时间之前删除文件，或完全不允许删除
5.11.4. 控制谁可以读取或删除这些数据对于维护安全的备份策略至关重要
5.11.5. 建议允许所有数据库机器写入，但没有机器能够读取或删除。分别或同时控制受限账户、机器的读取和删除
5.12. 自动扩展磁盘
5.12.1. 对于网络连接的磁盘，需要为预分配的而不是已使用的空间付费
5.12.2. 一种优化方法是将磁盘空间使用率目标提到更高的百分比
6. 合规性
6.1. DBA的工作并不局限于在业务运行时管理这些数据，还需要帮助企业保护数据，并使数据符合法律要求，或获得对企业至关重要的监管认证
6.2. 合规是一个涉及政策和控制的广泛领域，对每种政策和控制的解释也很多
6.3. GRC
6.3.1. 治理（Governance）
6.3.2. 风险管理（Risk management）
6.3.3. 合规性（Compliance）
6.4. 控制是公司内部定义的流程和规则，用于减少意外风险结果发生的概率
6.5. 合规性的构建是一个持续的过程，在需要的时候不容易“添加”
6.6. 法规法案
6.6.1. 服务组织控制类型2（SOC 2）
6.6.2. 2002年发布的萨班斯-奥克斯利法案（SOX）
6.6.3. 支付卡行业数据安全标准（PCI-DSS）
6.6.4. 1996年发布的《健康保险可携带性和责任法案》（HIPAA）
6.6.5. 联邦风险和授权管理计划（FedRAMP）
6.6.6. 通用数据保护条例（GDPR）是欧盟于2016年推出的
6.6.7. 2020年，欧盟司法法院裁决了欧盟和Facebook爱尔兰分部之间的一桩案件。这项通常被称为Schrems II
6.7. 不要共享用户
6.7.1. 不要跨服务共享数据库凭据
6.8. 不要在代码仓库中提交生产数据库凭据
6.8.1. 一种常见的做法是在合并一个pull请求之前，扫描代码库寻找潜在的机密字符串（GitHub等代码仓库托管服务可以实现
6.9. 确保密码始终以加密方式而不是以明文形式存储
6.9.1. 机密信息的长度做了限制，如果想存储比数据库的用户和密码对更长的内容，可能会导致意外
6.10. 区域的可用性
6.11. 角色与数据分离
6.11.1. 基于数据泄露将给企业或客户带来的风险等级对数据进行分离
6.12. 出于合规性原因进行分片
6.13. 独立的数据库用户
6.14. 跟踪变更
6.14.1. 很多合规性法规都附带了跟踪变更的控制措施
6.15. 很多合规性法规都附带了跟踪变更的控制措施
6.16. ⑩数据访问日志
6.16.1. 要求维护特定数据集的变更日志或访问日志
6.16.2. Percona审计日志插件是Percona发行的MySQL分支的一部分，但是默认情况下没有安装或启用
6.17. ⑾schema变更的版本控制
6.18. 建议设置这样一个策略：“删除六个月内未连接过数据库的用户”。这一做法将有助于防止使用不需要的、现在已成为负担的访问
7. 不建议使用触发器
7.1. 触发器会导致写性能下降，这会在最糟糕的时候对性能造成影响
7.2. 触发器相当于在数据库中存储业务逻辑，这是不推荐的
7.3. 在数据库中存储代码可能会绕过测试、转移和部署代码的任何过程。触发器可能意外地导致故障
7.4. 触发器只能支持跟踪写入操作。无法扩展成可以跟踪读取访问的解决方案
1. 事务日志
1.1. 事务日志有助于提高事务的效率
1.1.1. 存储引擎只需要更改内存中的数据副本，而不用每次修改磁盘中的表，这会非常快
1.1.2. 更改的记录写入事务日志中，事务日志会被持久化保存在硬盘上
1.2. 事务日志采用的是追加写操作，是在硬盘中一小块区域内的顺序I/O，而不是需要写多个地方的随机I/O，所以写入事务日志是一种相对较快的操作
1.3. 大多数使用这种技术（write-ahead logging，预写式日志）的存储引擎修改数据最终需要写入磁盘两次
1.4. 如果修改操作已经写入事务日志，那么即使系统在数据本身写入硬盘之前发生崩溃，存储引擎仍可在重新启动时恢复更改
2. MySQL中的事务
2.1. 自动提交模式
2.1.1. AUTOCOMMIT
2.1.2. 通过禁用此模式，可以在事务中执行一系列语句，并在结束时执行COMMIT提交事务或ROLLBACK回滚事务
2.2. 可以使用SET命令设置AUTOCOMMIT变量来启用或禁用自动提交模式
2.2.1. 启用可以设置为1或者ON
2.2.2. 禁用可以设置为0或者OFF
2.3. AUTOCOMMIT=0，则当前连接总是会处于某个事务中，直到发出COMMIT或者ROLLBACK，然后MySQL会立即启动一个新的事务
2.4. 除了在禁用AUTOCOMMIT的事务中可以使用之外，其他任何时候都不要显式地执行LOCK TABLES，不管使用的是什么存储引擎
2.5. 执行SET TRANSACTION ISOLATION LEVEL命令来设置隔离级别
2.5.1. 新的隔离级别会在下一个事务开始的时候生效
2.5.2. 最好在服务器级别设置最常用的隔离，并且只在显式情况下修改
2.6. MySQL不在服务器层管理事务，事务是由下层的存储引擎实现的
2.6.1. 在同一个事务中，混合使用多种存储引擎是不可靠的
2.6.2. 为每张表选择合适的存储引擎，并不惜一切代价避免在应用中混合使用存储引擎是非常重要的
2.6.3. 在非事务表中执行事务相关操作的时候，MySQL通常不会发出提醒，也不会报错
2.6.4. 最好不要在应用程序中混合使用存储引擎
2.6.4.1. 失败的事务可能导致不一致的结果，因为某些部分可以回滚，而其他部分不能回滚
2.7. InnoDB使用两阶段锁定协议
2.7.1. two-phase locking protocol
2.7.2. 在事务执行期间，随时都可以获取锁
2.7.3. 但锁只有在提交或回滚后才会释放，并且所有的锁会同时释放
2.8. InnoDB还支持通过特定的语句进行显式锁定
2.8.1. 不属于SQL规范
2.9. 支持LOCK TABLES和UNLOCK TABLES命令，这些命令在服务器级别而不在存储引擎中实现
2.10. 应该使用支持事务的存储引擎
2.10.1. InnoDB支持行级锁，所以没必要使用LOCKTABLES
3. 多版本并发控制
3.1. MVCC
3.2. 行级锁的一个变种
3.2.1. 在很多情况下避免了加锁操作，因此开销更低
3.2.2. 不仅实现了非阻塞的读操作，写操作也只锁定必要的行
3.3. Undo日志写入是服务器崩溃恢复过程的一部分，并且是事务性的
3.3.1. 所有Undo日志写入也都会写入Redo日志
3.3.2. Redo日志和Undo日志的大小也是高并发事务工作机制中的重要影响因素
3.4. 仅适用于REPEATABLE READ和READ COMMITTED隔离级别
3.5. READ UNCOMMITTED与MVCC不兼容
3.5.1. 查询不会读取适合其事务版本的行版本，而是不管怎样都读最新版本
3.6. SERIALIZABLE与MVCC也不兼容
3.6.1. 读取会锁定它们返回的每一行
4. 复制
4.1. 一种原生方式来将一个节点执行的写操作分发到其他节点
4.2. 对于在生产环境中运行的任何数据，都应该使用复制并至少有三个以上的副本
4.3. 理想情况下应该分布在不同的地区（在云托管环境中，称为region）用于灾难恢复计划
5. 数据文件结构
5.1. 在8.0版本中
5.1.1. 将表的元数据重新设计为一种数据字典
5.1.1.1. 在表的.ibd文件中
5.1.1.2. 减少了I/O，非常高效
5.1.2. 删除了基于文件的表元数据存储
5.2. 引入了字典对象缓存
5.2.1. 基于最近最少使用（LRU）的内存缓存
5.2.1.1. 分区定义
5.2.1.2. 表定义
5.2.1.3. 存储程序定义
5.2.1.4. 字符集
5.2.1.5. 排序信息
5.2.2. 当前访问最活跃的那些表，在缓存中最常出现
5.2.2.1. 每个表的.ibd和.frm文件被替换为已经被序列化的字典信息（.sdi）
5.3. 原子DDL
5.3.1. MySQL 8.0引入了原子数据定义更改
5.3.2. 数据定义语句现在要么全部成功完成，要么全部失败回滚
6. InnoDB引擎
6.1. MySQL主要的改进核心在于InnoDB的演进
6.1.1. 表元数据、用户认证、身份鉴权这些内部统计信息的管理也已经调整为使用InnoDB表来实现
6.2. MySQL的默认事务型存储引擎
6.2.1. 现在已经成为金标准，是推荐使用的引擎
6.2.2. 最重要、使用最广泛的引擎
6.2.3. 为处理大量短期事务而设计的，这些事务通常是正常提交的，很少会被回滚
6.2.4. 几乎能覆盖每一种使用场景
6.3. 最佳实践是使用InnoDB存储引擎作为所有应用程序的默认引擎
6.4. 将数据存储在一系列的数据文件中，这些文件统被称为表空间（tablespace）
6.4.1. 表空间本质上是一个由InnoDB自己管理的黑盒
6.5. 使用MVCC来实现高并发性，并实现了所有4个SQL标准隔离级别
6.5.1. 默认为REPEATABLE READ隔离级别
6.5.2. 通过间隙锁（next-key locking）策略来防止在这个隔离级别上的幻读
6.5.2.1. 不只锁定在查询中涉及的行，还会对索引结构中的间隙进行锁定，以防止幻行被插入
6.6. InnoDB表是基于聚簇索引构建的
6.6.1. 聚簇索引提供了非常快速的主键查找
6.7. 通过一些机制和工具支持真正的在线“热”备份
6.7.1. Oracle专有的MySQL Enterprise Backup
6.7.2. 开源的Percona XtraBackup
6.8. 引入了SQL函数来支持在JSON文档上的丰富操作
1. 线程
1.1. MySQL服务端是多线程软件。它的每个组件都使用线程
1.2. 每个线程至少有两个唯一标识符
1.2.1. 操作系统线程ID
1.2.2. MySQL内部线程ID
2. 对象类型
2.1. OBJECT_TYPE列
2.2. EVENT
2.3. FUNCTION
2.4. PROCEDURE
2.5. TABLE
2.6. TRIGGER
3. Performance Schema
3.1. 一个经常受到批评的特性
3.1.1. 早期版本的MySQL对其的实现不够理想，导致资源消耗较高
3.2. 提供了有关MySQL服务器内部运行的操作上的底层指标
3.3. 应该启用Performance Schema，按需动态地启用插桩和消费者表，通过它们提供的数据可以解决可能存在的任何问题——查询性能、锁定、磁盘I/O、错误等
3.4. 充分利用sys schema是解决常见问题的捷径。这样做将为你提供一种可以直接从MySQL中测量性能的方法
3.5. 程序插桩（instrument）
3.6. 消费者表（consumer）
3.7. 测量结果存储在Performance Schema数据库的多个表中
3.7.1. MySQL 8.0.25社区版的performance_schema中包含110个表
3.8. 摘要是一种通过删除查询中的变量来聚合查询的方法
3.9. 实例表（Instance）
3.9.1. 实例是指对象实例，用于MySQL安装程序
3.10. 设置表（Setup）
3.10.1. 用于performance_schema的运行时设置
3.11. metadata_locks表保存关于元数据锁的数据
3.12. Performance Schema收集的数据保存在内存中
3.13. 标准MySQL发行版包括一个和performance_schema数据配套使用的sys schema，它全部基于performance_schema上的视图和存储例程组成
3.14. 要启用或禁用Performance Schema，可以将变量performance_schema设置为ON或OFF
3.15. 启用或禁用performance_schema插桩
3.15.1. 使用setup_instruments表
3.15.1.1. 使用UPDATE语句更改instruments表的对应列值
3.15.2. 调用sys schema中的ps_setup_enable_instrument存储过程
3.15.2.1. ps_setup_enable_instrument
3.15.2.2. ps_setup_disable_instrument
3.15.3. 使用performance-schema-instrument启动参数
3.15.3.1. 变量支持performance-schema-instrument='instrument_name=value'这样的语法
3.16. 启用或禁用消费者表
3.16.1. 使用Performance Schema中的setup_consumers表
3.16.2. 调用sys     schema中的ps_setup_enable_consumer或ps_setup_disable_consuper存储过程
3.16.3. 使用performance-schema-consumer启动参数
3.17. 事务执行期间会一直持有元数据锁
3.17.1. 要启用元数据锁监测，需要启用wait/lock/meta-data/sql/mdl插桩
4. 升级MySQL
4.1. 新版本和稳定性之间的权衡
4.1.1. MySQL社区的长期成员Stewart Smith创造了著名的dot-20规则
4.1.2. 一款软件在dot-20版本发布之前永远不会真正成熟。
4.2. 进行版本升级是一个有风险的过程
4.2.1. 包括备份所有数据、测试更改，然后运行升级过程
4.3. 大版本的升级可能会让人望而却步
4.4. 升级的原因
4.4.1. 安全漏洞
4.4.1.1. 随着时间的推移，这种可能性会越来越小，但人们仍然有可能在MySQL中发现安全漏洞
4.4.2. 已知的bug
4.4.2.1. 在生产环境中遇到未知或无法解释的行为时，我们建议你确定当前运行的MySQL版本，然后阅读后续版本到最新版本的发布说明
4.4.3. 新功能
4.4.3.1. MySQL并不总是遵循严格的主要（major）/次要（minor）/点（point）的版本发布策略来添加功能
4.4.4. MySQL支持周期的终止
4.4.4.1. 建议保持在受支持的版本内，以便至少仍支持安全修复
4.5. 升级步骤
4.5.1. 制订一个计划
4.5.2. 阅读该版本的发行说明，包括任何微小的更改
4.5.3. 阅读官方文档中的升级说明
4.5.4. 对新版本进行测试
4.5.5. 最后执行升级
4.6. 降级
4.6.1. 对于所有主要和次要的版本变更（例如，从8.0降级到5.7或从5.7降级到5.6），降级的唯一方法是恢复升级前的备份
4.6.2. 自从MySQL 8.0以来，不能再降级点发布版本
4.6.3. 如果你运行的是8.0.25版本，除非导出所有数据并重新导入，否则不能再降级到8.0.24
4.7. 工具
4.7.1. Percona Toolkit提供的工具pt-upgrade
4.8. 最好的使用方法是首先使用慢速查询日志或二进制日志收集最关注的查询
4.9. 与直接登录到每台服务器相比，自动化可以使升级过程易于重复，并且效率更高，而且因出现拼写错误或者到错误的服务器上执行升级而导致意外停机的概率也更低
5. Kubernetes
5.1. 在Kubernetes技术流行之前，许多公司要么完全定制技术栈来供应和管理虚拟机和物理服务器，要么只完成了将资源生命周期管理一小部分的开源项目黏合在一起
5.2. MySQL不应该是在组织中Kubernetes上运行工作负载的第一个实验对象
1. 服务级别帮助你定义客户满意的程度和标准，以便你在解决性能、可扩展性挑战等事情与开发内部工具之间做出时间权衡
2. 服务水平指标（SLI）
2.1. 如何衡量客户是否满意
3. 服务水平目标（SLO）
3.1. 为了确保客户满意，能允许SLI达到的最低限度是多少
3.2. 将特定的SLI视为健康服务的目标范围
3.2.1. 必须定义为给定时间范围内的一个具体值，以确保每个人都对SLO的含义保持一致的理解
3.2.2. 如果SLI的指标是服务正常运行的时间，那么在给定的时间范围内，运行时间达到几个9就是SLO
4. 服务水平协议（SLA）
4.1. 我同意的SLO会产生什么后果
4.1.1. SLA是可选的
4.2. 与一个或多个业务客户（付费客户，而非内部利益相关者）签订的协议中包含的SLO，如果未满足该SLA，将受到财务或其他处罚
4.3. 如果团队没有达到其承诺的SLO，则不应继续进行新特性的工作
5. 怎样才能让客户满意
5.1. 目标是定义确保客户满意的最低标准
5.2. 选择指标和目标的目的是随时使用客观指标评估团队是否能够利用新功能进行创新，或者稳定性是否有可能降至客户可接受的水平以下，因此需要更多的关注和资源
5.3. 承诺的“9”越多，就越难实现，团队为实现这一承诺所花费的工程时间也就越昂贵
5.4. 达到3个9的可用性
5.4.1. 一年中的3个9相当于8个多小时的停机时间
5.4.2. 转换到一周则只有10分钟
5.5. 999图
Image

5.6. 工程时间是有限的资源
5.6.1. 选择SLO时必须注意不要过于追求完美
5.6.2. 将工程时间花在新功能上
5.6.3. 将时间花在可恢复性和修复问题上
5.7. 不是产品中的所有特性都需要这么多个9才能让客户满意
5.7.1. 随着产品特性集的增长，将会有不同的SLI和SLO，具体取决于特定功能的影响或其带来的收入
5.8. 区分不同用户的需求，以便可以为他们提供合理的SLI和SLO
5.8.1. 检测数据集何时成为不同用户的不同查询概要文件（query profile）的瓶颈，从而影响性能
6. 有效管理MySQL的一个关键点在于对数据库的健康状况进行良好的监控
7. 可用性
7.1. 能够无错误地响应客户的请求
7.1.1. 明确成功的响应
7.1.1.1. 200响应代码
7.1.2. 成功接受请求并承诺异步完成相关工作的响应
7.1.2.1. 202已接受
7.2. 没有要求必须做到100%，因为我们在一个不可避免失败的世界中运作
7.3. 不应该用一个指标来确定所有要求
7.4. 如果一个供应商的竞争优势是分析MySQL性能的特定任务，那么付费是可以给组织带来回报的
7.4.1. SolarWinds数据库性能管理工具
7.5. Percona监控和管理工具是一个成熟的开源选项
7.5.1. PMM
7.5.2. 仪表盘的组织是由Percona社区在监控MySQL性能方面的长期经验指导的
7.6. 将数据库慢查询日志和MySQL PerformanceSchema的输出信息发送到一个集中的位置，然后可以使用像pt-query-digest（Percona Toolkit包中的工具）这样的成熟工具来分析日志，并更深入地了解数据库实例在哪些方面花费了时间
7.7. 在性能倒退的情况下，花费生产之外的精力去调查“发生了什么”远比试图重新创建一个模拟更大代码路径的基准测试套件要具体得多
7.8. 可用性转换为数据库架构的SLI和SLO时
7.8.1. 在处理不可避免的灾难性故障时，哪些功能是不可协商的，哪些功能是“最好拥有的”
7.8.2. 将哪些类型的失败定义为“灾难性的”
7.8.3. “降级功能”是什么样子的
7.8.4. 给定一组可能的故障场景
7.9. 验证可用性的首选方法是从客户端或远程端点来进行访问
7.10. MySQL中有一个Threads_running状态计数器可以作为可用性问题的关键指标
7.11. Thread_running与max_connections的差距，将此差距作为另一个数据点，以检查正在进行的工作是否过载
8. 监控查询延迟
8.1. MySQL引入了许多长期需要的增强功能来跟踪查询运行所需的时间
9. 监控报错
9.1. MySQL客户端在访问运行着的服务的过程中出现错误并不一定意味着服务遭到破坏
9.2. 间歇性错误，通过简单地重试失败的查询就可以解决这些错误
9.3. 错误发生的频率可能是潜在问题的关键指标
9.3.1. 如果报错的频率加快，则是将要出现问题的迹象
9.4. Lock wait timeout
9.4.1. 如果客户端中该报错急剧增加，可能是主节点上的行级锁争用在不断扩大，即事务不断重试但仍然失败
9.4.2. 可能是无法写入的前兆
9.5. Aborted connections
9.5.1. 如果客户端中该报错突然激增，可能表明客户端和数据库实例之间的某个访问层出现了问题
9.5.2. 跟踪这一点会导致大量客户端重试，这会消耗资源
9.6. too many connections
9.7. 操作系统级别的“cannot create new thread
9.8. 应用程序创建和打开的连接数超过了数据库服务器配置中允许的连接数，这个限制可能来自服务器的max_connections变量或者MySQL进程被允许打开的线程数
10. 主动监控
10.1. 不要将所有精力都集中在显示事故发生的指标上，而是应花一些时间来监控可以帮助预防事故的事情
10.2. 磁盘空间使用率增长
10.2.1. 设置多个阈值，其中较低的警告可以设置为仅在工作时间触发，而较高的、更严重的值则作为对非工作时间随叫随到的告警
10.3. 连接数增长
10.3.1. 流量不断增长时，数据库服务器可以支持有限的连接池，这被配置为服务器参数max_connections
10.3.2. 应用程序层打开了大量未使用的连接，导致产生了毫无理由的连接过多的风险
10.3.2.1. 连接的线程数（threads_connected）很高，但运行的线程数（threads_running）仍然很低
10.3.3. 应用程序层正在积极地使用大量的连接，并有导致数据库过载的风险
10.3.3.1. 连接的线程数（threads_connected）和运行的线程数（threads_running）都处于高值并持续增加
10.4. 复制延迟
10.4.1. 能够被视为一种重要的SLI指标，它能引起异常事故
10.4.2. 复制延迟可能会使数据看起来不一致
10.4.3. 即使复制延迟从未达到影响客户体验的程度，如果偶然出现，这仍然是一个比较明显的迹象，说明当前配置下源节点写入设备的性能要强于副本节点，这可能预示系统写容量出现不足
10.5. I/O使用率
10.5.1. “尽可能多地在内存中工作，因为这样更快”
10.5.1.1. 数据库工程师不断努力的目标之一
10.5.2. 不要从磁盘读取太多的数据，否则查询就只能等待那些宝贵的I/O周期
10.5.3. iostat这样的工具可以监控I/O等待
10.5.4. 如果数据库服务器有很多线程位于IOwait状态，则需要监控发出告警，这表示它们正在队列中等待某些磁盘资源可用
10.6. 自增键空间
10.6.1. 自动递增主键在默认情况下被创建为有符号整数，并且可能会耗尽键空间
10.6.2. 为所有使用自增主键的表监控剩余整数空间是一个简单的操作，但几乎可以肯定的一点是，它会在将来为你避免一些重大事故，因为可以提前预测需要更大的键空间
10.6.3. 使用了PMM及其Prometheus导出器（exporter），那么已经自带监控方法，你需要做的就是开启collect.auto_increment.columns设置
10.7. 创建备份/恢复时间
10.7.1. 监控将备份从文件恢复到运行的数据库（该数据库自创建备份以来还一直在复制所有更改）需要多长时间
10.7.2. 功能分片（Functional sharding）是指将服务于特定业务功能的特定表分割到一个专用的集群中，以便单独管理该数据集的正常运行时间、性能甚至访问控制
10.7.3. 水平分片（Horizontal sharding）是指当数据集的大小超过了可以在单个集群中可靠地提供服务的规模时，将它拆分为多个集群，并从多个节点提供数据，这依赖于某种查找机制来定位所需的数据子集
11. 长期性能
11.1. 业务节奏
11.1.1. 业务节奏可能意味着峰值流量时间比“平均值”大几个数量级，如果数据库基础架构没有准备好，将产生很多不良结果
11.1.2. 业务周期可能会因业务所满足的客户需求而大不相同
11.1.3. 了解业务周期以及对业务收入、声誉的影响至关重要
11.2. 业务的长期规划
11.2.1. 为未来的容量做规划
11.2.2. 预见何时需要重大改进，何时增量修改就够了
11.2.3. 为运行基础架构增加的成本做规划
11.3. 提高透明度，重点是跟踪结果而不是输出
11.4. 对平均值说不
11.4.1. 平均值的数据点图很可能会让你产生错误的安全感
11.5. 与百分位为友
11.5.1. 百分位依赖于在给定的时间范围内对数据点进行排序，并根据目标百分位移除最高值的数据点（例如，如果要寻找95百分位，则移除最顶端的5%）
11.6. 使用SLO来指导整体架构
11.6.1. 在业务增长的同时保持良好一致的客户体验不是一件容易的事
11.6.2. 随着业务规模的增长，保持相同的SLO都将变得越来越困难，更不用说制定更雄心勃勃的SLO了
11.6.3. 你希望实现的SLO越严格，工作成本就越高，因为每秒的数据库事务数峰值或数据量也会呈数量级的方式增长
1. 从软件本身和它运行的典型工作负载来看，MySQL通常也更适合运行在廉价硬件上
2. 基本资源
2.1. CPU
2.2. 内存
2.3. 磁盘
2.4. 瓶颈
2.5. 网络资源
3. CPU
3.1. 最常见的瓶颈是CPU耗尽
3.2. 检查CPU使用率来确定工作负载是否受CPU限制
3.3. 低延迟（快速响应时间）
3.3.1. 需要更快的CPU，因为每个查询将只使用一个CPU
3.4. 高吞吐量
3.4.1. 如果可以同时运行多个查询，那么可以使用多个CPU为查询提供服务
4. 内存
4.1. 内存耗尽的情况也会发生，但通常只在你试图将太多内存分配给MySQL时才会发生
4.2. 配置大内存的主要原因并不是为了在内存中保存大量数据，而是为了避免磁盘I/O
4.3. 磁盘I/O比访问内存中的数据要慢几个数量级
4.4. 如果有足够的内存，可以完全避开磁盘读取操作
4.5. 如果所有数据都能装入内存，那么一旦服务器的缓存预热完成，每次读取都将是一次缓存命中
4.6. 写入可以像读取一样在内存中执行，但迟早必须被写入磁盘，才能持久保留数据
4.7. 缓存可以延迟写操作，但缓存不能像消除读操作那样消除写操作
4.8. 多次写操作，一次刷新
4.8.1. 一个数据片段可以在内存中被多次更改，而无须每一次都将新值写入磁盘
4.8.2. 当数据被最终刷新到磁盘时，自上次物理写入以来发生的所有修改都将被持久化
4.9. I/O合并
4.9.1. 许多不同的数据片段可以在内存中被修改，这些修改可以被收集在一起，因此物理写可以作为单个磁盘操作执行
4.9.2. 提前写日志（write-ahead logging）策略
4.9.2.1. 允许在内存中更改页面，而不用将更改刷新到磁盘，这通常涉及随机I/O，速度非常慢
4.9.2.2. 将更改的记录写入顺序日志文件，这样要快得多
4.9.2.3. 后台线程可以稍后将修改过的页面刷新到磁盘，这样做可以优化写操作的性能
4.10. 写操作从缓冲中获益，因为可以将随机I/O转换为顺序I/O
4.11. 异步（缓冲）写操作通常由操作系统处理，并且是被成批处理的，因此可以更优地被刷新到磁盘
4.12. 同步（无缓冲）写入必须等待数据落盘
5. 固态（闪存）存储
5.1. I/O饱和也会发生，但比CPU耗尽的频率低得多
5.2. 用HDD硬盘时，最好尝试找到一个有效的内存/磁盘比率
5.2.1. HDD延迟较高、IOPS较低
5.3. 使用SSD时，内存对磁盘的比率就变得不那么重要了
5.4. 固态设备对于提高服务器整体性能非常有用，现在通常应该成为数据库的标准配置，尤其对于OLTP工作负载
5.4.1. SSD通常比HDD快10到20倍
5.4.2. 只有在预算极为有限的系统中，或者在需要惊人的高达数PB的磁盘空间的数据仓库场景下，才考虑继续使用HDD
5.5. 比硬盘驱动器明显更好的随机读写性能
5.6. 闪存设备读的能力通常略好于写的能力
5.7. 比硬盘驱动器更好的顺序读写性能
5.8. 比硬盘驱动器更好的并发支持
5.8.1. 只有在拥有大量并发性的情况下，闪存设备才能真正实现最高吞吐量
5.9. 固态存储设备使用非易失性闪存芯片组成的单元
5.9.1. 非易失随机访问内存（NVRAM）
5.10. 固态存储建立在闪存之上
5.11. 闪存的特点
5.11.1. 可以被快速地多次读取，而且以很小的单元读取数据
5.11.2. 写入则要困难得多
5.11.2.1. 只有进行特殊的擦除操作之后，存储单元才能被重新写入数据，并且每次擦除的块大小较大
5.12. 写操作的限制是固态存储复杂性的原因
5.12.1. 为了使写操作能够很好地执行，并避免过早地耗尽闪存块写寿命，设备必须能够重新定位页面，并执行垃圾收集和所谓的损耗均衡
5.13. 为了使某些块保持新鲜并为新的写入做好准备，设备会回收块
5.14. 100GB文件在160GB的SSD上的性能与在320GB的SSD上的性能是不同的
5.14.1. 当没有空闲块时，必须等待擦除操作完成，从而导致速度减慢
5.14.2. 写入空闲块需要几百微秒，但擦除速度要慢得多，通常需要几毫秒
6. RAID
6.1. 存储引擎通常将数据/索引保存在单个大文件中，这意味着RAID通常是存储大量数据的最佳选项
6.2. 不要认为RAID是数据安全方面的强有力的保证
6.2.1. RAID并不能消除，甚至不能减少备份的需要
6.3. 保存在损坏的物理媒介中的数据很少被访问，可能几个月都不会被发现，直到尝试读取数据，或者当另一个驱动器出现故障，RAID控制器尝试使用损坏的数据重建阵列时才发现问题
6.3.1. 硬盘空间越大，出现这种情况的可能性就越大
6.4. 大多数控制器都提供了一些软件来报告阵列的状态，你需要对此进行跟踪，否则可能完全不知道驱动器已出现故障
6.4.1. 到第二个驱动器出现故障时就太晚了
6.5. 通过定期主动检查阵列的一致性，可以降低潜在的损坏风险
6.6. 很多RAID控制器不能很好地处理大数据块
6.7. RAID缓存是物理安装在硬件RAID控制器上的（相对）少量内存
6.7.1. 在RAID缓存中缓存读取都是浪费内存
6.8. RAID控制器的内存是一种稀缺资源，应该明智地使用它
6.9. 对事务日志发出fsync()调用，并在启用sync_binlog的情况下创建二进制日志，但除非控制器有备用电池单元（BBU）或其他非易失性存储，否则不应启用写缓存
6.9.1. 硬盘也可能会撒谎。应该确保在fsync()时刷新缓存，或者干脆在没有备用电池时禁用它们
6.9.2. 当安装新硬件时，最好进行真正的暴力碰撞测试（例如把电源插头拔出来）。这通常是发现细微的错误配置或偷偷摸摸的硬盘行为的唯一方法
6.10. 要测试RAID控制器的BBU是否真的可靠，请确保将电源线拔下一段时间
6.10.1. 有些BBU设备在没电的情况下无法维持足够的时间（将RAID缓存的数据刷新到磁盘
6.10.2. 一个环节出问题可能会导致整个存储系统链变得无用
6.11. RAID 0
6.11.1. 最便宜和性能最好的RAID配置
6.11.2. 永远不适合用于生产数据库
6.11.3. 在开发环境中，当服务器完全失效也不会变成突发事件时，可以选择RAID 0
6.11.4. 不提供任何冗余
6.11.5. RAID 0阵列的故障概率高于任何单磁盘的故障概率，而不是更低
6.12. RAID 1
6.12.1. 良好的读性能，并且可以跨磁盘复制数据
6.12.2. 良好的冗余
6.12.3. 读取速度略高于RAID 0
6.12.4. 顺序写入不需要许多底层磁盘就能执行得很好
6.12.5. 需要冗余但只有两个硬盘驱动器的低端服务器的典型选择
6.12.6. 大多数操作系统都允许你轻松地创建软件RAID 0和RAID 1卷
6.13. RAID 5
6.13.1. 将数据分布在具有分布式奇偶校验块的多块磁盘上，以便在任何一块磁盘出现故障时，可以从奇偶校验块重建数据
6.13.2. 如果两块磁盘同时出现故障，整个卷将无法恢复
6.13.2.1. 丢失两块磁盘时会产生灾难性的后果
6.13.3. RAID 5的可伸缩性不能超过10块磁盘
6.13.4. 良好的RAID 5的性能在很大程度上依赖于RAID控制器的缓存，这可能与数据库服务器的需求相冲突
6.14. RAID 6
6.14.1. 允许你在承受两次磁盘故障的情况下仍然能重建阵列
6.14.2. 计算额外的奇偶校验会使写操作比RAID 5慢
6.15. RAID 10
6.15.1. 一个非常好的数据存储选择
6.15.2. 条带化的镜像对组成，因此在读写方面都能很好地被扩展
6.15.2.1. 最佳的条带块大小取决于工作负载和硬件
6.15.2.2. 对于随机I/O来说，拥有较大的块大小是很好的，因为这意味着可以从单个驱动器中满足更多的读取需求
6.15.3. 与RAID 5相比，它的重建速度快且容易
6.15.4. 以很好地在软件中被实现
6.16. RAID 50
6.16.1. 由条带化的RAID 5阵列组成，如果有很多磁盘，它可以很好地兼顾RAID 5的经济性和RAID 10的性能
6.16.2. 主要用于非常大的数据集，如数据仓库或非常大的OLTP系统
7. 网络
7.1. 延迟和带宽是网络连接的限制因素
7.2. 网络运行不正常是主要的性能瓶颈
7.3. 数据包丢失是一个常见的问题
7.3.1. 即使是1%的丢失也足以导致性能显著下降，因为协议栈中的各个层都会尝试通过等待一段时间然后重新发送数据包等策略来解决问题，这会增加额外的响应时间
7.4. DNS解析异常中断或缓慢成为一个致命弱点
7.4.1. 对于生产服务器来说，启用skip_name_resolve是一个好主意
7.4.2. 当MySQL收到连接请求时，它会同时进行正向和反向DNS查找
7.4.3. 如果启用skip_name_resolve选项，MySQL不会进行任何DNS查找
7.4.3.1. 意味着用户账号在host列中只能有IP地址、“localhost”或IP地址通配符
7.4.3.2. host列中包含主机名的任何用户账号都将无法登录
8. 文件系统
8.1. 文件系统是在数据库中保证数据完整性的最低层
8.2. Windows
8.2.1. 只有一个（NTFS）是真正可行的
8.3. GNU/Linux
8.3.1. 大多数时候，给定的文件系统跟其他文件系统相比不会有明显的差别
8.3.2. 只有在某些情况下，达到文件系统的处理极限时，例如，需要处理高并发性、处理许多文件、碎片，等等，不同文件系统的差异才会体现出来
8.3.3. 最好使用日志型文件系统，如ext4、XFS或ZFS
8.3.4. 建议使用XFS文件系统，并将交换率和磁盘队列调度器设置为适合于服务器的值
8.4. 磁盘队列调度器
8.4.1. 完全公平排队，即CFQ（Complete FairQueuing）
8.4.2. 在MySQL的工作负载类型下，CFQ会导致非常糟糕的响应时间，因为会不必要地阻塞队列中的一些请求
8.4.3. 不要使用CFQ，它可能会导致严重的性能问题
8.5. 内存和交换
8.5.1. 给MySQL分配大量内存后，它的表现最好
8.5.2. InnoDB使用内存作为缓存来避免磁盘访问
8.5.2.1. 意味着内存系统的性能会直接影响查询的速度
8.5.3. 当使用SSD时，性能损失不像使用HDD时那样明显
8.5.3.1. 仍然应该积极地避免交换，即使只是为了避免不必要的写操作，因为写操作可能会缩短磁盘整体寿命
8.5.4. 更改存储引擎读写数据的方式
8.5.4.1. 设置innodb_flush_method=O_DIRECT可以减轻I/O压力
8.5.4.2. 该参数仅对InnoDB有效
8.6. 很多技巧都是特定于内核版本的，所以要小心，特别是在升级时
8.7. Linux剖析器perf是一个非常有用的工具，可以用它来检查操作在系统级别发生的事情
1. 除非遇到异常情况，否则不需要调整配置
1.1. 不要“调优”服务器，不要使用比率、公式或“调优脚本”作为设置配置变量的基础
1.1.1. 在互联网上搜索配置建议并不总是一个好主意，你会在博客、论坛等找到很多糟糕的建议
1.1.2. 很难判断谁是真正的专家
1.1.3. 不要相信流行的内存消耗公式
1.2. 可靠的、有信誉的MySQL服务提供商通常比简单的互联网搜索结果更安全，因为那些需要拥有满意的客户的人可能正在做正确的事情
1.2.1. 即使是他们的建议，在没有经过测试和理解的情况下进行应用也可能是危险的，因为它可能针对的是一种与你不同的情况，而你却没有理解
1.3. MySQL的不同版本会删除、弃用和更改一些选项，欲了解详细信息请查看相关文档
1.4. 应该始终通过阅读相关的官方手册来检查任何更改并仔细测试
1.5. MySQL有许多可以更改但不应该更改的设置
1.5.1. MySQL的默认设置是有充分理由的
1.5.2. 修改配置的潜在缺点可能是巨大的
1.5.3. 很多默认设置都是安全的，很多人都会直接使用。这使默认设置成为测试最彻底的设置。当没必要改变这些设置而改变它们时，可能会引起意想不到的错误
1.5.4. 节省时间和避免麻烦的好方法是使用默认设置，除非你明确知道不应该使用默认设置
1.6. 更好的做法是正确地配置基本设置（在大多数情况下，只有少数设置是重要的），并将更多的时间花在schema优化、索引和查询设计上
1.7. 如果问题是由服务器的某个部分引起的，而该部分的行为可以通过配置选项进行纠正，那么可能需要对其进行更改
1.8. 应该只在发现它们解决的特定性能问题时，才设置它们
1.9. 如果需要改进配置，应该会在查询响应时间中体现出来
1.10. 最好从查询及其响应时间开始分析，而不是从配置选项开始
1.10.1. 节省很多时间，避免很多问题
2. 专用数据库服务器
2.1. 可以设置的最佳选项是innodb_dedicated_server
2.1.1. 可以处理90%的性能配置
2.1.2. 配置了4个额外的变量（innodb_buffer_pool_size、innodb_log_file_size、innodb_log_files_in_group和innodb_flush_method）
2.1.3. 通常会占用50%～75%的内存
2.1.3.1. MySQL只需要少量的内存就能保持一个连接（通常是一个相关的专用线程）打开
2.2. 无法使用innodb_dedicated_server
2.2.1. innodb_buffer_pool_size
2.2.1.1. InnoDB缓冲池大小
2.2.1.2. 需要的内存比其他任何组件都多
2.2.1.3. 不仅缓存索引，还缓存行数据、自适应哈希索引、更改缓冲区、锁和其他内部结构等
2.2.1.4. InnoDB严重依赖缓冲池，应该确保为其分配足够的内存
2.2.1.5. 大型缓冲池会带来一些挑战，比如更长的关闭时间和预热时间
2.2.1.6. 当MySQL再次启动时，缓冲池缓存是空的，也称为冷缓存
2.2.1.7. 默认情况下，innodb_buffer_pool_dump_at_shutdown和innodb_buffer_pool_load_at_startup这两个配置可以配合使用，以在启动时预热缓存池
2.2.2. innodb_log_file_size
2.2.2.1. 日志文件大小
2.2.3. 解决了我们所看到的绝大多数实际配置问题
2.3. 应该设置一些安全选项
2.3.1. 通常不会提高性能，只会避免问题
3. MySQL的配置
3.1. 需要永久使用的任何设置都应该写入全局配置文件，而不是在命令行中指定
3.2. 将所有配置文件保存在一个地方也是一个好主意，这样可以方便地检查它们
3.3. 一定要知道服务器的配置文件在哪里
3.3.1. Debian服务器上默认不存在/etc/my.cnf，而是会在/etc/mysql/my.cnf中查找配置
3.4. 配置文件采用标准INI格式，被分为多个部分，每个部分都以一行包含在方括号中的该部分名称开头
3.5. 配置设置全部用小写字母书写，单词之间以下画线或短横线分隔
3.5.1. 建议选择一种风格并始终如一地使用它
3.6. 全局作用域
3.7. 会话作用域
3.8. 许多会话作用域的变量都有相应的全局变量，可以将相应的全局变量的值视为会话变量的默认值
3.9. 动态配置变量
3.9.1. 很多变量（但不是全部）还可以在服务器运行时进行更改
3.9.2. 如果重新启动MySQL，即使使用了SET GLOBAL来更改全局变量，它也将恢复到配置文件中的状态
3.9.3. 必须同时管理MySQL的配置文件和运行时配置，并确保它们保持同步
3.10. MySQL 8.0引入了一个名为持久化系统变量的新功能
3.10.1. 新的语法SET PERSIST允许在运行时设置一次值，MySQL将把这个设置写入磁盘，以便在下次重启后继续使用该值
3.11. table_open_cache
3.11.1. 设置此变量不会立即生效：下一次线程打开表时，MySQL会检查变量的值
3.11.2. 如果该值大于缓存中的表的数目，线程可以将新打开的表插入缓存
3.11.3. 如果该值小于缓存中的表的数目，MySQL将从缓存中删除未使用的表
3.12. thread_cache_size
3.12.1. 设置此变量不会立即生效：下一次关闭连接时，MySQL会检查缓存中是否有空间来存储线程
3.12.2. 如果有，则缓存线程以供其他连接将来重用
3.12.3. 如果没有，则将线程终止而不是缓存它
3.12.4. 只有当查询需要时，MySQL才会为该缓冲区分配内存，而且会立即分配此变量指定的整块内存
3.12.5. 每个处于线程缓存或休眠状态的线程通常使用大约256KB内存
3.12.6. 通常应该保持线程缓存足够大，这样Threads_created就不会经常增加
3.13. open_files_limit选项
3.13.1. 典型的Linux系统中，我们将其设置得尽可能大
3.13.2. 在现代操作系统中，打开文件句柄的成本很低
3.13.3. 如果这个设置不够大，就会看到经典的24号错误，“too many openfiles”
3.14. 设置变量时要小心。并不总是越多越好
3.15. 理想情况下，应该使用版本控制系统来跟踪配置文件的更改
3.16. MySQL并不是一个严格控制内存分配的数据库服务器
3.16.1. 事实是，你不能给MySQL的内存消耗设定上限
4. I/O行为
4.1. InnoDB不仅允许你控制其恢复方式，还允许控制其打开和刷新数据的方式，这将极大地影响恢复和总体性能
4.2. InnoDB使用日志来降低提交事务的成本
4.3. InnoDB假定它使用的是传统的磁盘，随机I/O比顺序I/O的开销要大很多，因为随机I/O需要在磁盘上寻找正确的位置，并等待将所需的磁盘部分旋转到磁头下
4.4. InnoDB最终必须将更改的数据写入数据文件
4.4.1. 日志的大小固定，采取的是循环写入的方式
4.4.1.1. 当到达日志的末尾时，它会环绕到日志的开头
4.4.1.2. 如果日志记录中包含的更改尚未应用于数据文件，则无法覆盖日志记录，因为这将删除已提交事务的唯一永久记录
4.5. 日志文件的总大小由innodb_log_file_size和innodb_log_files_in_group控制，这对写入性能非常重要
4.6. 当缓冲区满了、事务提交时，或者每秒1次（这三个条件以先满足者为准），InnoDB会将缓冲区刷新到磁盘上的日志文件中
4.7. 不需要将缓冲区设置得太大
4.7.1. 建议的范围是1～8M B
4.8. innodb_flush_log_at_trx_commit
4.8.1. 1
4.8.1.1. 每次事务提交时，将日志缓冲区写入日志文件，并将其刷新到持久存储中
4.8.1.2. 默认的（也是最安全的）设置
4.8.1.3. 保证你不会丢失任何已提交的事务，除非磁盘或操作系统“假装”进行刷新操作（没有将数据真正写入磁盘）
4.8.1.3.1. 如果驱动器断电，数据仍可能丢失
4.8.2. 0
4.8.2.1. 每秒定时将日志缓冲区写入日志文件，并刷新日志文件，但在事务提交时不做任何操作
4.8.3. 2
4.8.3.1. 与0设置最重要的区别是，如果只是MySQL进程崩溃，设置为2不会丢失任何事务。但是，如果整个服务器崩溃或断电，仍然可能丢失事务
4.8.4. 设置为0和2通常会导致最多1秒的数据丢失，因为数据可能只存在于操作系统的缓存中
4.9. 高性能事务需求的最佳配置是将innodb_flush_log_at_trx_commit设置为1，并将日志文件放在具有备用电池的写缓存和SSD的RAID卷上，这既安全又非常快
4.10. 最好为日志文件和数据文件分别提供一个配置选项，但目前是组合在一起的
4.11. 如果你使用的是类UNIX操作系统，并且RAID控制器有备用电池的写缓存，我们建议使用O_DIRECT
4.12. 如果不是，则default或O_DIRECT都可能是最佳选择，具体取决于应用程序
5. InnoDB表空间
5.1. 表空间本质上是一个虚拟文件系统，由磁盘上的一个或多个文件组成
5.2. 包含了Undo日志（重新创建旧行版本所需的信息）、修改缓冲区、双写缓冲区和其他内部结构
5.3. 对日志文件也非常严格
5.4. innodb_file_per_table
5.4.1. 提供了额外的可管理性和可视性
5.4.2. 通过检查单个文件来查找表的大小要比使用SHOWTABLE STATUS快得多
5.4.3. SHOW TABLE STATUS必须执行更复杂的工作来确定为一个表分配了空间
5.4.4. 会使DROPTABLE性能变差。严重时可能导致服务器范围内明显的停顿
5.4.4.1. 先将.ibd文件链接到一个大小为零的文件，然后手动删除该文件，而不是等待MySQL来删除
5.4.4.2. 从8.0.23版本开始，这应该不再是一个问题了
5.5. 表空间在写操作频繁的环境中可能会变得非常大
5.5.1. 要限制写操作，请将innodb_max_purge_lag变量设置为0以外的值
5.5.1.1. 表示在InnoDB开始延迟更多修改数据的查询之前，可以等待清除的最大事务数
5.5.1.2. 设置innodb_max_purge_lag变量也会降低性能
5.5.2. 未清除的行版本会影响所有查询，因为它们会使表和索引变大
5.5.3. 清除线程不能跟上进度，性能就会下降
5.5.4. 默认的可重复读取事务隔离级别，InnoDB将无法删除行的旧版本，因为未提交的事务仍需要能够看到它们
5.5.5. 清除过程是多线程的，但如果遇到清除延迟问题（innodb_purge_threads和innodb_purge_batch_size），则可能需要针对工作负载进行调优
5.5.6. 如果Undo日志很大，并且表空间因此而增长，你可以强制MySQL放慢速度来让InnoDB的清理线程跟上
5.5.6.1. InnoDB会不断地写入数据并填充磁盘，直到磁盘空间耗尽或者表空间达到所定义的上限
5.6. sync_binlog选项控制MySQL如何将二进制日志刷新到磁盘，默认值是1
5.6.1. MySQL将执行刷新并保持二进制日志的持久性和安全性
5.6.2. 不建议设置为任何其他值
6. MySQL并发
6.1. 如果遇到InnoDB并发问题，并且运行的MySQL版本低于5.7，解决方案通常是升级服务器
6.2. 如果你发现自己遇到了并发性瓶颈，最好的选择是对数据进行分片
6.2.1. 如果分片不可行，那么可能需要限制并发性
6.3. 限制并发性的最基本方法是使用innodb_thread_concurrency变量，该变量限制了内核中同时可以有多少线程
6.3.1. 首先将innodb_thread_concurrency设置为与可用CPU核数相同的值，然后根据需要调整大小
7. 安全设置
7.1. 安全性和可靠性的保障成本往往更高
7.2. max_connect_errors
7.2.1. 如果网络暂时出现问题、出现应用程序或配置错误，或者存在另一个问题导致连接无法在短时间内成功完成，则客户端可能会被阻止连接，并且在刷新主机缓存之前无法再次连接
7.2.2. 默认设置（100）非常小，因此该问题很容易发生
7.2.3. 如果启用了skip_name_resolve，则max_connect_errors选项将无效，因为其行为取决于主机缓存，而主机缓存被skip_name_resolve禁用
7.3. skip_name_resolve
7.3.1. DNS是MySQL连接过程中的一个薄弱环节
7.3.2. 某个时间点出现DNS故障的概率几乎是确定性的
7.4. max_connections
7.4.1. 设置得足够高，以满足你认为将要经历的正常负载的连接需求，并且额外保留一些连接以便管理服务器时可以登录
7.4.2. 默认值为151，这对于很多应用程序来说都不够
7.4.3. 如果没有使用持久连接，但是应用程序没有正常断开连接，也会出现服务器连接占满的情况
7.4.4. 可以显示服务器是否在某个时刻出现了连接高峰。如果到达max_connections，则客户端可能至少被拒绝了一次
7.5. sql_mode
7.5.1. 最好让MySQL在大多数方面保持原样，而不要试图让它像其他数据库服务器那样运行
7.5.2. 在计划升级数据库时，一定要检查对默认sql_mode的更改
7.6. sysdate_is_now
7.6.1. 如果你不是明确地希望SYSDATE()函数具有不确定性行为（这会破坏复制并使从备份中进行的时间点恢复变得不可靠），那么可以启用该选项并使其行为具有确定性
7.7. read_only
7.7.1. 可防止未经授权的用户对副本进行更改，副本应仅通过复制而不是从应用程序接收更改
7.7.2. 建议将副本设置为只读模式
7.8. super_read_only
7.8.1. 可阻止拥有SUPER权限的用户写入数据
7.8.2. 启用此功能后，唯一可以将更改写入数据库的就是复制
7.8.3. 建议启用super_read_only
7.8.4. 防止你意外地使用管理员账户将数据写入只读副本，从而引起数据不同步
8. 高级InnoDB设置
8.1. innodb_autoinc_lock_mode
8.1.1. 控制InnoDB如何生成自动递增的主键值
8.2. innodb_buffer_pool_instances
8.2.1. 将缓冲池划分为多个段，这可能是提高多核机器上MySQL在高并发工作负载下可伸缩性最重要的方法之一
8.2.2. 多个缓冲池对工作负载进行分区，这样一些全局互斥体就不会成为争用热点
8.3. innodb_io_capacity
8.3.1. 告知InnoDB有多少I/O容量可供其使用
8.4. innodb_read_io_threads
8.5. innodb_write_io_threads
8.6. 如果你有很多硬盘和高并发工作负载，并且发现线程很难跟上，那么可以增加线程的数量，或者简单地将它们设置为执行I/O操作的物理磁盘数量
8.7. innodb_strict_mode
8.7.1. InnoDB在某些情况下抛出错误而不是警告，尤其是无效或可能导致危险的CREATE TABLE选项
8.8. innodb_old_blocks_time
8.8.1. 一个由两部分组成的缓冲池LRU列表，设计目的是防止临时查询将长期多次使用的页面驱逐出去
8.8.2. 默认情况下，它被设置为0
8.8.3. 将其设置为一个较小的值如1000（1秒），这在基准测试中被证明是非常有效的
1. 良好的逻辑设计和物理设计是高性能的基石
1.1. 反范式的schema可以加速某些类型的查询，但同时可能减慢其他类型的查询
1.2. 添加计数器和汇总表是一个优化查询的好方法，但它们的维护成本可能很
1.3. 将修改schema作为一个常见事件来规划
2. 让事情尽可能小而简单是一个好主意
2.1. 尽量避免在设计中出现极端情况
2.2. 使用小的、简单的、适当的数据类型，并避免使用NULL，除非确实是对真实数据进行建模的正确方法
2.3. 尝试使用相同的数据类型来存储相似或相关的值，尤其是在联接条件中使用这些值时
2.4. 注意可变长度字符串，它可能会导致临时表和排序的全长内存分配不乐观
2.5. 如果可能的话，尝试使用整数作为标识符
2.6. 小心使用ENUM和SET类型
2.7. 避免使用BIT类型
3. 选择正确的数据类型对于获得高性能至关重要
3.1. 更小的通常更好
3.1.1. 尽量使用能够正确存储和表示数据的最小数据类型
3.1.2. 更小的数据类型通常更快，因为它们占用的磁盘、内存和CPU缓存的空间更少，并且处理时需要的CPU周期也更少
3.1.3. 在schema中的多个地方增加数据类型范围是一个痛苦且耗时的操作
3.1.4. 如果无法确定哪个数据类型是最好的，请选择你认为不会超过的最小数据类型
3.2. 简单为好
3.2.1. 简单数据类型的操作通常需要更少的CPU周期
3.2.2. 整型数据比字符型数据的比较操作代价更低
3.2.2.1. 字符集和排序规则（collation）使字符型数据的比较更复杂
3.2.2.2. 应该将日期和时间存储为MySQL的内置类型而不是字符串类型
3.2.2.3. 应该用整型数据存储IP地址
3.3. 尽量避免存储NULL
3.3.1. 最好指定列为NOT NULL，除非明确需要存储NULL值
3.3.2. 如果查询中包含可为NULL的列，对MySQL来说更难优化，因为可为NULL的列使得索引、索引统计和值比较都更复杂
3.3.3. 可为NULL的列会使用更多的存储空间，在MySQL里也需要特殊处理
3.3.4. 可为NULL的列改为NOT NULL带来的性能提升比较小
4. 整数类型
4.1. 整数（whole number）
4.1.1. TINYINT、SMALLINT、MEDIUMINT、INT或BIGINT
4.1.1.1. 使用8、16、24、32和64位存储空间
4.1.2. 整数类型有可选的UNSIGNED属性，表示不允许负值，这大致可以使正数的上限提高一倍
4.1.3. 有符号和无符号类型使用相同的存储空间，并具有相同的性能，因此可以根据数据实际范围选择合适的类型
4.1.4. 整数计算通常使用64位的BIGINT整数
4.1.5. 对于存储和计算来说，INT（1）和INT（20）是相同的
4.1.6. 一些大容量的场景，可以考虑使用BIGINT代替DECIMAL，将需要存储的货币单位根据小数的位数乘以相应的倍数即可
4.1.7. 存储财务数据并精确到万分之一分，则可以把所有金额乘以一百万，然后将结果存储在BIGINT里
4.1.8. 同时避免浮点存储计算不精确和DECIMAL精确计算代价高的问题
4.2. 实数（real number，带有小数部分的数字）
4.2.1. 不仅适用于带小数的数字，也可以使用DECIMAL存储比BIGINT还大的整数
4.2.2. 浮点类型通常比DECIMAL使用更少的空间来存储相同范围的值
4.2.3. FLOAT列使用4字节的存储空间
4.2.4. DOUBLE占用8字节，比FLOAT具有更高的精度和更大的值范围
4.2.5. 应该尽量只在对小数进行精确计算时才使用DECIMAL
5. 字符串类型
5.1. 字符串长度定义的不是字节数，是字符数
5.2. VARCHAR
5.2.1. 用于存储可变长度的字符串，是最常见的字符串数据类型
5.2.2. 它比固定长度的类型更节省空间，因为它仅使用必要的空间
5.2.3. 更少的空间用于存储更短的值
5.2.4. 需要额外使用1或2字节记录字符串的长度
5.2.4.1. VARCHAR（1000）的列则需要1002个字节，因为需要2字节存储长度信息
5.2.5. 节省了存储空间，所以对性能也有帮助
5.2.5.1. 由于行是可变长度的，在更新时可能会增长，这会导致额外的工作
5.2.6. 推荐使用场景
5.2.6.1. 字符串列的最大长度远大于平均长度
5.2.6.2. 列的更新很少，所以碎片不是问题
5.2.6.3. 使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储
5.3. CHAR
5.3.1. 总是为定义的字符串长度分配足够的空间
5.3.2. 当存储CHAR值时，MySQL删除所有尾随空格
5.3.3. 如果需要进行比较，值会用空格填充
5.3.4. 推荐使用场景
5.3.4.1. 存储非常短的字符串
5.3.4.1.1. 对于非常短的列，CHAR也比VARCHAR更高效
5.3.4.1.2. 设计为只保存Y和N的值的CHAR（1）在单字节字符集中只使用1字节，但VARCHAR（1）需要2字节，因为还有一个记录长度的额外字节
5.3.4.2. 所有值的长度都几乎相同的情况
5.3.5. 对于经常修改的数据，CHAR也比VARCHAR更好，因为固定长度的行不容易出现碎片
5.4. 二进制字符串与常规字符串非常相似，但它们存储的是字节而不是字符
5.5. 填充也不同：MySQL填充BINANRY用的是\0（零字节）而不是空格，并且在检索时不会去除填充值
5.6. 字节比较的优势
5.6.1. 大小写不敏感
5.6.2. 二进制比较比字符比较简单得多，因此速度更快
5.7. BLOB和TEXT类型
5.7.1. 存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储
5.7.2. 字符类型
5.7.2.1. TINYTEXT、SMALLTEXT、TEXT、MEDIUMTEXT和LONGTEXT
5.7.2.2. TEXT是SMALLTEXT的同义词。
5.7.2.3. 有字符集和排序规则
5.7.3. 二进制类型
5.7.3.1. TINYBLOB、SMALLBLOB、BLOB、MEDIUMBLOB、LONGBLOB
5.7.3.2. BLOB是SMALLBLOB的同义词
5.7.3.3. 二进制数据，没有排序规则或字符集
5.7.3.4. 如果需要在检索后保持值不变，请小心使用BINARY类型，MySQL会使用\0将其填充到需要的长度
5.7.4. 当BLOB和TEXT值太大时，InnoDB会使用独立的“外部”存储区域，此时每个值在行内需要1～4字节的存储空间，然后在外部存储区域需要足够的空间来存储实际的值
5.7.5. 只对这些列的最前max_sort_length字节而不是整个字符串做排序
5.7.6. 不能将BLOB和TEXT数据类型的完整字符串放入索引，也不能使用索引进行排序
1. ENUM（枚举）
1.1. MySQL在存储枚举时非常紧凑，会根据列表值的数量压缩到1或者2字节中
1.2. 转换为ENUM会使表变小
1.3. 如果表中有其他索引，减少主键大小也会使这些非主键索引小得多
1.4. ENUM列可以存储一组预定义的不同字符串值
1.5. ENUM字段是根据内部整数值排序的，而不是根据字符串本身
1.6. 查询中使用FIELD()函数显式地指定排序顺序，但这会导致MySQL无法利用索引消除排序
1.7. MySQL将每个枚举值存储为整数，并且必须进行查找以将其转换为字符串表示，因此ENUM列有一些开销
1.8. 将CHAR/VARCHAR列联接到ENUM列可能比联接到另一个CHAR/VARCHAR列更慢
1.9. 通常的设计实践是使用带有整数主键的“查找表”，以避免在联接中使用字符串
1.10. 更改ENUM中的有效值会导致需要做schema变更
2. 日期和时间类型
2.1. MySQL可以存储的最小时间粒度是微秒
2.2. DATETIME
2.2.1. 从1000年到9999年，精度为1微秒
2.2.2. 以YYYYMMDDHHMMSS格式存储压缩成整数的日期和时间
2.2.3. 与时区无关
2.2.4. 8字节的存储空间
2.2.5. 以可排序、无歧义的格式显示DATETIME值
2.2.6. ANSI表示日期和时间的标准方式
2.2.7. 保留日期和时间的文本表示
2.3. TIMESTAMP
2.3.1. 自1970年1月1日格林尼治标准时间（GMT）午夜以来经过的秒数
2.3.1.1. 与UNIX时间戳相同
2.3.2. 从1970年到2038年1月19日
2.3.2.1. 会遇到2038年的问题
2.3.2.1.1. 使用带符号的32位INT，可以表达直到2038年的时间
2.3.2.1.2. 使用无符号的32位INT，可以表达直到2106年的时间
2.3.2.1.3. 使用64位，还可以超出这些范围
2.3.3. 时间戳显示的值依赖于时区
2.3.3.1. MySQL服务器、操作系统和客户端连接都有时区设置
2.3.3.2. 存储值0的TIMESTAMP在美国东部标准时间（EST）中显示为1969-12-31   19：00：00，与格林尼治标准时间（GMT）差5小时
2.3.4. 4字节的存储空间
2.3.5. FROM_UNIXTIME()函数来将UNIX时间戳转换为日期
2.3.6. UNIX_TIMESTAMP()函数将日期转换为UNIX时间戳
2.3.7. 保留与所使用时区相关的值
2.3.8. TIMESTAMP的行为规则很复杂，并且在不同的MySQL版本中会发生变化，因此你应该验证数据库的行为是否符合需要。在对TIMESTAMP列进行更改后，通常最好检查SHOW CREATE TABLE命令的输出
2.3.9. 特殊属性
2.3.9.1. 当插入一行记录时没有指定第一个TIMESTAMP列的值，MySQL会将该列的值设置为当前时间
2.3.9.2. 当更新一行记录时没有指定第一个TIMESTAMP列的值，MySQL默认也会将该列的值更新为当前时间
2.3.9.3. 可以为任何TIMESTAMP列配置插入和更新行为
2.3.9.4. TIMESTAMP列在默认情况下为NOT NULL，这也和其他的数据类型不一样
3. 位压缩数据类型
3.1. 从技术上来说都是字符串类型
3.2. BIT
3.2.1. 可以使用BIT列存储一个或多个true/false值
3.2.2. 视为字符串类型，而不是数字类型
3.2.3. 避免使用这种类型
3.2.3.1. 建议使用TINYINT
3.3. SET
3.3.1. 如果需要存储多个true/false值，可以考虑使用MySQL原生的SET数据类型
3.3.2. 以一组打包的位的集合来表示的
3.3.3. 更有效地利用存储空间
3.3.4. FIND_IN_SET()和FIELD()等函数，使其易于在查询中使用
3.3.5. 替代方法是使用整数作为二进制位的打包集合
3.3.5.1. 可以在不使用ALTER TABLE的情况下更改字段表示的“枚举”
3.3.5.2. 查询更难编写和理解
4. JSON数据类型
4.1. 决定使用原生SQL还是JSON取决于在数据库中存储JSON的便捷性是否大于性能
4.2. 如果每天访问这些数据数百万次或数十亿次，速度差异就会累加起来
4.3. 使用SQL列的速度仍然更好于JSON列
5. 标识符
5.1. 引用行及通常使其唯一的方式
5.2. 为标识符列选择数据类型时，应该与联接表中的对应列保持一致
5.3. 在为标识符列选择类型时，不仅需要考虑存储类型，还需要考虑MySQL如何对该类型执行计算和比较
5.4. 在可以满足值的范围的需求，并且预留未来增长空间的前提下，应该选择最小的数据类型
5.5. 整数通常是标识符的最佳选择
5.5.1. 速度快
5.5.2. 自动递增
5.6. 对于标识符来说，ENUM和SET类型通常是糟糕的选择
5.6.1. ENUM和SET列适用于保存订单状态或产品类型等信息
5.7. 应避免使用字符串类型作为标识符的数据类型
5.7.1. 很消耗空间
5.7.2. 比整数类型慢
5.8. 对于完全“随机”的字符串要非常小心
5.8.1. MD5()、SHA1()或UUID()生成的字符串
5.9. 新值会任意分布在很大的空间内，这会减慢INSERT和某些类型的SELECT查询的速度
5.9.1. 插入的值会写到索引的随机位置，所以会使得INSERT查询变慢
5.9.2. 导致页分裂、磁盘随机访问，以及对于聚簇存储引擎产生聚簇索引碎片
5.9.3. SELECT查询也会变慢，因为逻辑上相邻的行会广泛分布在磁盘和内存中
5.9.4. 对于所有类型的查询，随机值都会导致缓存的性能低下，因为它们会破坏引用的局部性，而这正是缓存的工作原理
5.10. 存储通用唯一标识符（UUID）值，则应该删除破折号
5.10.1. 更好的做法是，使用UNHEX()函数将UUID值转换为16字节的数字，并将其存储在一个BINARY（16）列中
5.10.2. 可以使用HEX()函数以十六进制格式检索值
6. 特殊数据类型
6.1. IPv4地址
6.1.1. 使用VARCHAR（15）列来存储
6.1.2. 实际上是32位无符号整数，而不是字符串
6.1.2.1. 小数点将地址分成四段的表示方法只是为了让人们阅读容易
6.1.2.2. 存储为无符号整数
6.1.3. INET_ATON()和INET_NTOA()函数来在这两种表示形式之间进行转换
6.1.4. 从VARCHAR（15）的约16字节缩减到无符号32位整数的4字节
7. schema设计中的陷阱
7.1. 太多的列
7.2. 太多的联接
7.2.1. MySQL限制每个联接有61个表
7.3. 全能的枚举
7.3.1. 要小心过度使用ENUM
7.4. 变相的枚举
7.4.1. ENUM列允许在列中保存一组已定义值中的单个值
7.4.2. SET列则允许在列中保存一组已定义值中的一个或多个值
7.4.3. 如果真和假两种情况不会同时出现，那么毫无疑问应该使用ENUM列而不是SET列
7.5. NULL不是虚拟值
7.5.1. 在表中存储事实上的“空值”，可以使用0、特殊值或空字符串作为代替
7.5.2. 当需要表示未知值时，不要太害怕使用NULL
7.5.3. 在某些情况下，使用NULL比使用某个虚拟常数更好
7.5.4. MySQL会对NULL值进行索引，而Oracle则不会
8. schema管理
8.1. 修改schema是数据库工程师必须承担的最常见任务之一
8.2. schema变更管理视为“数据存储平台”的一部分
8.3. 尽可能靠近现有的软件部署工具和工作流程
8.4. 应该使用能够集成针对schema更改的基本检测的工具，以确保满足一些基线需求
8.5. 如果所在的组织使用多种编程语言且发展迅速，请确保不会意外地引入人为瓶颈
8.6. Skeema是一个在跨多个环境的版本控制中管理schema更改的杰出开源解决方案
8.7. gh-ost是由GitHub的数据工程团队创建的，专门作为一种管理schema更改过程的解决方案，既不影响服务，也不使用触发器
8.7.1. 其使用的是二进制日志而不是触发跟踪变化，这是更安全的选择，所以不必担心触发器的性能影响
1. 索引
1.1. 键（key）
1.2. 存储引擎用于快速找到记录的一种数据结构
1.3. 当表中的数据量越来越大时，索引对性能的影响愈发重要
1.4. 在数据量较小且负载较低时，缺少合适的索引对性能的影响可能还不明显
1.5. 索引优化是对查询性能优化最有效的手段
1.6. 索引能够轻易将查询性能提高几个数量级
1.7. “最优”的索引有时比一个“好的”索引性能要好两个数量级
1.8. 创建一个真正“最优”的索引经常需要重写查询
1.9. 可以包含一列或多列的值
1.10. 包含多列，那么列的顺序也十分重要
1.10.1. MySQL只能有效地使用索引的最左前缀列
1.11. 在精妙和复杂的索引面前，无论ORM工具多么精巧，都不要对其抱太大希望
1.12. 即使是查询优化技术专家也很难兼顾到各种情况，更别说ORM了
2. 索引的类型
2.1. 在MySQL中，索引是在存储引擎层而不是服务器层实现的
2.2. 不同存储引擎的索引的工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引
2.3. 在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足不同类型的查询需求
2.4. B-tree索引
2.4.1. 使用B-tree数据结构来存储数据
2.4.2. 意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同
2.4.2.1. 按照索引列中的数据大小顺序存储的
2.4.3. 适用于全键值、键值范围或键前缀查找
2.4.3.1. 键前缀查找只适用于根据最左前缀的查找
2.4.4. 能够加快数据访问的速度
2.4.4.1. 在查询某些条件的数据时，存储引擎不再需要进行全表扫描
2.4.4.2. 通过比较节点页的值和要查找的值可以找到合适的指针进入下层子节点，这些指针实际上定义了子节点页中值的上限和下限
2.4.4.3. 最终存储引擎要么找到对应的值，要么该记录不存在
2.4.5. NDB集群存储引擎虽然依然使用了BTREE标识，但在其内部实际上使用了T-tree结构存储这种索引
2.4.6. InnoDB则使用的是B+tree
2.5. 自适应哈希索引
2.5.1. 当InnoDB发现某些索引值被非常频繁地被访问时，它会在原有的B-tree索引之上，在内存中再构建一个哈希索引
2.5.2. 让B-tree索引也具备了一些哈希索引的优势实现非常快速的哈希查找
2.5.3. 完全自动化的，用户无法进行控制或者配置
2.5.4. 可以通过参数彻底关闭自适应哈希索引这个特性
2.6. 全文索引
2.6.1. FULLTEXT
2.6.2. 查找的是文本中的关键词，而不是直接比较索引中的值
2.6.3. 全文索引和其他几类索引的匹配方式完全不一样
2.6.4. 全文索引更类似于搜索引擎做的事情，而不是简单的WHERE条件匹配
2.6.5. 在相同的列上同时创建全文索引和基于值的B-tree索引并不会有冲突
2.6.6. 全文索引适用于MATCH AGAINST操作，而不是普通的WHERE条件操作
3. 索引优点
3.1. 可以让服务器快速地定位到表的指定位置
3.2. 索引大大减少了服务器需要扫描的数据量
3.3. 索引可以帮助服务器避免排序和临时表
3.4. 索引可以将随机I/O变为顺序I/O
4. 高性能的索引策略
4.1. 正确地创建和使用索引是实现高性能查询的基础
4.2. 索引的选择性
4.2.1. 不重复的索引值（也称为基数，cardinality）和数据表的记录总数（＃T）的比值，范围从1/＃T到1之间
4.2.2. 索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行
4.2.3. 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的
4.3. 前缀索引
4.3.1. 一种能使索引更小、更快的有效办法
4.3.2. 有时候为了提升索引的性能，同时也节省索引空间，可以只对字段的前一部分字符进行索引
4.3.3. 对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL并不支持对这些列的完整内容进行索引
4.3.4. 缺点
4.3.4.1. 会降低索引的选择性
4.3.4.2. MySQL无法使用前缀索引做ORDER BY和GROUP BY操作，也无法使用前缀索引做覆盖扫描
4.3.5. 既要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）
4.3.6. 计算合适的前缀长度的办法就是计算完整列的选择性，并使前缀的选择性接近完整列的选择性
4.3.7. 只看平均选择性是不够的，还有例外的情况，需要考虑最坏情况下的选择性
4.3.8. 常见的场景是针对很长的十六进制唯一ID使用前缀索引
4.4. 多列索引
4.4.1. 一个常见的错误就是，为每列创建独立的索引，或者按照错误的顺序创建多列索引
4.4.2. 在多列上独立地创建多个单列索引，在大部分情况下并不能提高MySQL的查询性能
4.4.3. 用UNION改写查询，往往是最好的办法
4.5. 选择合适的索引列顺序
4.5.1. 正确的顺序依赖于使用该索引的查询语句
4.5.1.1. 还需要考虑如何更好地满足排序和分组操作的需要
4.5.2. 索引列的顺序意味着索引首先按照最左列进行排序，其次是第二列
4.5.3. 索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的ORDER BY、GROUP BY和DISTINCT等子句的查询需求
4.5.4. 当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的
4.5.5. 经验法则考虑的是全局基数和选择性，而不是某个具体查询
4.5.6. 性能不只依赖于所有索引列的选择性（整体基数），也和查询条件的具体值有关，也就是和值的分布有关
4.5.7. 经验法则和推论在多数情况下是有用的，但要注意，不要假设平均情况下的性能也能代表特殊情况下的性能，特殊情况可能会摧毁整个应用的性能
5. 聚簇索引
5.1. 并不是一种单独的索引类型，而是一种数据存储方式
5.2. InnoDB的聚簇索引实际上在同一个结构中保存了B-tree索引和数据行
5.3. 聚簇表示数据行和相邻的键值紧凑地存储在一起
5.4. 因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引
5.5. 如果你没有定义主键，InnoDB会选择一个唯一的非空索引代替
5.6. 如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引
5.7. 优点
5.7.1. 以把相互关联的数据保存在一起
5.7.2. 数据访问更快
5.7.2.1. 从聚簇索引中获取数据通常比在非聚簇索引中查找要快
5.7.3. 使用覆盖索引扫描的查询可以直接使用页节点中的主键值
5.7.4. 聚簇数据最大限度地提高了I/O密集型应用的性能
5.7.4.1. 如果数据全部都放在内存中，则访问的顺序就没那么重要了，聚簇索引也就没什么优势了
5.8. 缺点
5.8.1. 插入速度严重依赖于插入顺序
5.8.2. 更新聚簇索引列的代价很高
5.8.2.1. 会强制InnoDB将每个被更新的行移动到新的位置
5.8.3. 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临页分裂（page split）的问题
5.8.4. 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候
5.9. 最好避免随机的（不连续且值的分布范围非常大）聚簇索引，特别是对于I/O密集型的应用
5.10. 从性能的角度考虑，使用UUID作为聚簇索引会很糟糕
5.10.1. 主键字段更长
5.10.2. 占用的空间也更大
5.10.2.1. 页分裂和碎片
5.11. 对于高并发的工作负载，在InnoDB中按主键顺序插入可能会造成明显的写入竞争
5.11.1. 主键的上界会成为“热点”
5.11.2. 所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争
5.12. AUTO_INCREMENT锁机制
5.12.1. 可能需要考虑重新设计表或者应用，或者更改innodb_autoinc_lock_mode配置
6. 二级索引
6.1. 二级索引（非聚簇索引）可能比想象中的要更大，因为二级索引的叶子节点包含了引用行的主键列
6.2. 二级索引访问需要两次索引查找，而不是一次
1. 覆盖索引
1.1. 设计优秀的索引应该考虑到整个查询，而不单是WHERE条件部分
1.2. 如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为覆盖索引
1.3. 只有B-tree索引可以用于覆盖索引
1.4. 如果查询只需要扫描索引而无须回表
1.4.1. 索引条目通常远小于数据行大小，所以如果只需要读取索引，那么MySQL就会极大地减少数据访问量
1.4.2. 覆盖索引对于I/O密集型的应用也有帮助，因为索引比数据更小，更容易全部放入内存中
1.4.3. 因为索引是按照列值的顺序存储的（至少在单页内如此），所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少得多
1.4.4. 由于InnoDB的聚簇索引的特点，覆盖索引对InnoDB表特别有用
1.4.4.1. InnoDB的二级索引在叶子节点中保存了记录的主键值，所以如果二级索引能够覆盖查询，则可以避免对主键索引的二次查询
1.5. 在索引中满足查询的成本一般比查询记录本身要小得多
2. 使用索引扫描来做排序
2.1. 生成有序的结果
2.1.1. 通过排序操作
2.1.2. 按索引顺序扫描
2.2. 如果索引不能覆盖查询所需的全部列，那么就不得不每扫描一条索引记录都回表查询一次对应的记录
2.2.1. 基本上都是随机I/O
2.2.2. 按索引顺序读取数据的速度通常要比顺序地全表扫描慢，尤其是在I/O密集型的应用负载上
2.3. 只有当索引的顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向（倒序或正序）都一样时，MySQL才能使用索引来对结果做排序
2.4. 如果前导列为常量的时候，ORDER BY子句中的列也可以不满足索引的最左前缀的要求
2.5. 如果在WHERE子句或者JOIN子句中将这些列指定为了常量，就可以“填补”索引字段的间隙了
2.6. 使用索引做排序的另一个最重要的场景是，查询语句中同时有ORDERBY和LIMIT子句的情况
3. 重复索引
3.1. 指在相同的列上按照相同顺序创建的相同类型的索引
3.2. MySQL允许在相同列上创建多个相同的索引
3.2.1. MySQL会抛出一个警告，但是并不会阻止你这么做
3.2.2. MySQL需要单独维护重复的索引，优化器在优化查询的时候也需要逐个地进行评估，这会影响性能，同时也浪费磁盘空间
4. 冗余索引
4.1. 如果创建了索引（A，B），再创建索引（A）就是冗余索引
4.1.1. 索引（A，B）也可以当作索引（A）来使用
4.1.2. 前一个索引的前缀索引
4.1.3. 这种冗余只是对B-tree索引来说的
4.2. 如果再创建索引（B，A），则不是冗余索引，索引（B）也不是，因为B不是索引（A，B）的最左前缀列
4.3. 将一个索引扩展为（A，ID），其中ID是主键，因为主键列已经包含在二级索引中了，所以这也是冗余的
4.4. 冗余索引通常发生在为表添加新索引的时候
4.5. 大多数情况下都不需要冗余索引，应该尽量扩展已有的索引而不是创建新的索引
4.6. 出于性能方面的考虑也需要冗余索引，因为扩展已有的索引会导致其变得太大，从而影响其他使用该索引的查询的性能
4.7. 索引越多，插入的速度越慢
4.7.1. 增加新索引会导致INSERT、UPDATE、DELETE等操作的速度变慢，特别是当新增索引后达到了内存瓶颈的时候
5. 未使用的索引
5.1. 一些服务器永远不用的索引
5.2. 这样的索引完全是累赘，建议删除
5.3. 找到未使用索引的最好办法就是使用系统数据库performance_schema和sys
5.4. 在sys数据库中，在table_io_waits_summary_by_index_usage视图中可以非常简单地知道哪些索引从来没有被使用过
6. 解决冗余索引和重复索引的方法
6.1. 删除这些索引就可以了
6.2. 针对INFORMATION_SCHEMA表编写各种复杂的查询来识别这类索引
6.3. Percona工具箱中的pt-duplicate-key-checker，该工具通过分析表结构来找出冗余和重复索引
6.4. 使用Percona工具箱中的pt-upgrade工具来仔细检查计划中的索引变更
6.5. 使用MySQL 8.0的不可见索引特性，而不是直接删除索引
6.5.1. 可以通过ALTER TABLE语句，改变索引的一个标志位，使得优化器在确定执行计划时，忽略该索引
6.5.2. 如果你发现计划删除的索引依旧有非常重要的作用，可以直接把索引改成可见，而不需要重新构建该索引
7. 维护索引和表
7.1. 找到并修复损坏的表
7.1.1. 对于数据表来说，最糟糕的情况就是表被损坏了
7.1.2. 损坏的索引会导致查询返回错误的结果或者出现莫须有的主键冲突等问题，严重时甚至还会导致数据库的崩溃
7.1.3. 可以尝试运行CHECK TABLE来检查是否发生了表损坏
7.1.4. 可以使用REPAIR TABLE命令来修复损坏的表
7.1.5. 如果是InnoDB存储引擎的表发生了损坏，那么一定是发生了严重的错误，需要立刻调查一下原因
7.1.5.1. 常见的类似错误通常是由于尝试使用rsync备份InnoDB导致的
7.1.6. 如果遇到数据损坏，最重要的是找出是什么导致了损坏，而不只是简单地修复，否则很有可能还会不断地出现数据损坏的情况
7.2. 维护准确的索引统计信息
7.2.1. MySQL的优化器使用的是基于成本的模型，而衡量成本的主要指标就是一个查询需要扫描多少行
7.2.2. 可以使用SHOW INDEX FROM命令来查看索引的基数（cardinality）
7.3. 减少索引和数据的碎片
7.3.1. B-tree索引可能会产生碎片化，这会降低查询的效率
7.3.2. 碎片化的索引可能会以很差或者无序的方式存储在磁盘上
7.3.3. 如果叶子页在物理分布上是顺序且紧密的，那么查询的性能就会更好
7.3.3.1. 否则，对于范围查询、索引覆盖扫描等操作来说，速度可能会降低很多
7.3.3.2. 对于索引覆盖扫描，这一点会表现得更加明显
7.3.4. 行碎片（Row fragmentation）
7.3.4.1. 数据行被存储在多个地方的多个片段中
7.3.4.2. 即使查询只从索引中访问一行记录，行碎片也会导致性能下降
7.3.5. 行间碎片（Intra-row fragmentation）
7.3.5.1. 指逻辑上顺序的页或者行，在磁盘上不是顺序存储的
7.3.5.2. 对诸如全表扫描和聚簇索引扫描之类的操作有很大的影响，因为这些操作原本能够从磁盘上顺序存储的数据中获益
7.3.6. 剩余空间碎片（Free space fragmentation）
7.3.6.1. 指数据页中有大量的空余空间
7.3.6.2. 导致服务器读取大量不需要的数据，从而造成浪费
7.3.6.3. 可以通过执行OPTIMIZE TABLE或者导出再导入的方式来重新整理数据
7.3.6.4. 对多数存储引擎都是有效的
8. 原则
8.1. 单行访问是很慢的，特别是在机械硬盘中存储
8.1.1. 尽可能选择合适的索引以避免单行查找
8.1.2. SSD的随机I/O要快很多，不过这一点仍然成立
8.2. 按顺序访问范围数据是很快的
8.2.1. 顺序I/O不需要多次磁盘寻道，所以比随机I/O要快很多（特别是对于机械硬盘）
8.2.2. 如果服务器能够按需顺序读取数据，那么就不再需要额外的排序操作，并且GROUP BY查询也无须再做排序和将行按组进行聚合计算了
8.3. 索引覆盖查询是很快的
8.3.1. 如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行
8.4. 建议按响应时间来对查询进行分析
8.4.1. 如果一个查询无法从所有可能的索引中获益，则应该看看是否可以创建一个更合适的索引来提升性能
